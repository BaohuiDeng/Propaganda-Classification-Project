{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: Predefined CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Propaganda:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,sentence,SUBJprop):\n",
    "        self.sentence = sentence\n",
    "        self.SUBJprop = SUBJprop\n",
    "        self.propaganda = self.get_propaganda()\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        if self.SUBJprop <=2:\n",
    "            return Propaganda.NEGATIVE\n",
    "        elif self.SUBJprop == 3:\n",
    "            return Propaganda.NEUTRAL\n",
    "        else:\n",
    "            return Propaganda.POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'NEGATIVE'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "reviews = []\n",
    "data  = pd.read_excel('Data/Dataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data, columns = ['Sentence','SUBJprop'])\n",
    "\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "\n",
    "reviews[0].sentence\n",
    "reviews[0].propaganda\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: Prep Data (split into train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991\n",
      "NEGATIVE\n",
      "496\n",
      "495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, test = train_test_split(reviews, train_size=0.7, random_state = 42 ) \n",
    "# len(training)\n",
    "print(len(test))\n",
    "print(training[0].propaganda)\n",
    "\n",
    "developmentSet, testSet = train_test_split(test, train_size=0.5, random_state = 42 ) \n",
    "print(len(testSet))\n",
    "print(len(developmentSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: Seperate the attribute, originally our array has text and score. we want them to be a seperate array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bey and serena have been running in the same circles since the 22time grammy winner was a member of destiny’s child\n",
      "NEGATIVE\n",
      "now theyre finally dating openly but reps for azalea are still lying about the relationship for some reason\n"
     ]
    }
   ],
   "source": [
    "train_sentence = [ x.sentence for x  in training]     # return just text\n",
    "train_propaganda = [x.propaganda for x in training]   # return just sentiment\n",
    "\n",
    "test_sentence = [x.sentence for x in testSet]\n",
    "test_propaganda = [x.propaganda for x in testSet]\n",
    "\n",
    "print(train_sentence[0])\n",
    "print(train_propaganda[0])\n",
    "print(test_sentence[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bey and serena have been running in the same circles since the 22time grammy winner was a member of destiny’s child\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_sentence) # return a matrix of either 0 or 1 # train_x is our text\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_sentence)\n",
    "\n",
    "print(train_sentence[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#step 4: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bey and serena have been running in the same circles since the 22time grammy winner was a member of destiny’s child\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_sentence) # return a matrix of either 0 or 1 # train_x is our text\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_sentence)\n",
    "\n",
    "print(train_sentence[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['NEGATIVE'], dtype='<U8')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "# test_y[0]\n",
    "clf_svm.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['NEGATIVE'], dtype='<U8')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['NEGATIVE'], dtype='<U8')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_log.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8911290322580645\n",
      "0.844758064516129\n",
      "0.9173387096774194\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "# For Support Vector Machine\n",
    "print(clf_svm.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Tree\n",
    "print(clf_dec.score(test_x_vectors,test_propaganda))\n",
    "# For Logistic Regression\n",
    "print(clf_log.score(test_x_vectors,test_propaganda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28571429 0.16       0.94462541]\n",
      "[0.04444444 0.23076923 0.92067039]\n",
      "[0.         0.06451613 0.95881732]\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(test_propaganda,clf_svm.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEUTRAL,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels\n",
    "\n",
    "# For Support Decision Tree\n",
    "print(f1_score(test_propaganda,clf_dec.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEUTRAL,Propaganda.NEGATIVE]))\n",
    "\n",
    "\n",
    "# For Logistic Regression\n",
    "print(f1_score(test_propaganda,clf_log.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEUTRAL,Propaganda.NEGATIVE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "2054\n"
     ]
    }
   ],
   "source": [
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['NEGATIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set =['this is advertisement','bad book do not buy','horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 7: Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_fit_time': array([0.84636238, 1.49004517, 0.91160223, 1.89543235, 0.77847877,\n        1.31340368, 0.59762824, 1.54938927, 0.6213877 , 1.52501931,\n        0.64342873, 1.3120312 ]),\n 'std_fit_time': array([0.28788896, 0.1376422 , 0.16620883, 0.22314054, 0.33003522,\n        0.08696788, 0.01741298, 0.30178669, 0.06933135, 0.35702647,\n        0.12767459, 0.10210445]),\n 'mean_score_time': array([0.07667377, 0.08826575, 0.06387362, 0.11037745, 0.07481987,\n        0.08449843, 0.04914193, 0.09488091, 0.05846941, 0.11652124,\n        0.05158501, 0.09362845]),\n 'std_score_time': array([0.05304824, 0.00270606, 0.01125454, 0.02537366, 0.03722528,\n        0.00172844, 0.00186313, 0.01594923, 0.02377313, 0.08558301,\n        0.00781735, 0.02116289]),\n 'param_C': masked_array(data=[1, 1, 4, 4, 8, 8, 16, 16, 32, 32, 64, 64],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf'],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'C': 1, 'kernel': 'linear'},\n  {'C': 1, 'kernel': 'rbf'},\n  {'C': 4, 'kernel': 'linear'},\n  {'C': 4, 'kernel': 'rbf'},\n  {'C': 8, 'kernel': 'linear'},\n  {'C': 8, 'kernel': 'rbf'},\n  {'C': 16, 'kernel': 'linear'},\n  {'C': 16, 'kernel': 'rbf'},\n  {'C': 32, 'kernel': 'linear'},\n  {'C': 32, 'kernel': 'rbf'},\n  {'C': 64, 'kernel': 'linear'},\n  {'C': 64, 'kernel': 'rbf'}],\n 'split0_test_score': array([0.85775862, 0.88793103, 0.85775862, 0.89224138, 0.84913793,\n        0.89224138, 0.85775862, 0.89224138, 0.85344828, 0.89224138,\n        0.83189655, 0.89224138]),\n 'split1_test_score': array([0.85714286, 0.89177489, 0.83982684, 0.89177489, 0.83982684,\n        0.89177489, 0.84848485, 0.88744589, 0.83982684, 0.88744589,\n        0.81818182, 0.88744589]),\n 'split2_test_score': array([0.84848485, 0.89177489, 0.82683983, 0.88744589, 0.82683983,\n        0.88744589, 0.82683983, 0.88744589, 0.83116883, 0.88744589,\n        0.82683983, 0.88744589]),\n 'split3_test_score': array([0.87012987, 0.89177489, 0.86147186, 0.89177489, 0.86580087,\n        0.88311688, 0.86147186, 0.87445887, 0.86147186, 0.87012987,\n        0.83982684, 0.87012987]),\n 'split4_test_score': array([0.83982684, 0.88744589, 0.84415584, 0.88744589, 0.84415584,\n        0.88744589, 0.85281385, 0.88744589, 0.84848485, 0.88744589,\n        0.83116883, 0.88744589]),\n 'split5_test_score': array([0.86580087, 0.88744589, 0.85714286, 0.88744589, 0.85714286,\n        0.88744589, 0.85714286, 0.88311688, 0.84415584, 0.88311688,\n        0.80519481, 0.88311688]),\n 'split6_test_score': array([0.83116883, 0.88744589, 0.83549784, 0.88311688, 0.83549784,\n        0.88311688, 0.83982684, 0.88744589, 0.84415584, 0.88311688,\n        0.83116883, 0.88311688]),\n 'split7_test_score': array([0.86147186, 0.88744589, 0.86147186, 0.88744589, 0.86147186,\n        0.88744589, 0.86147186, 0.88744589, 0.85281385, 0.88311688,\n        0.81818182, 0.88311688]),\n 'split8_test_score': array([0.8961039 , 0.88744589, 0.87878788, 0.88744589, 0.87878788,\n        0.88744589, 0.87445887, 0.88311688, 0.87878788, 0.88311688,\n        0.86580087, 0.88311688]),\n 'split9_test_score': array([0.87878788, 0.88744589, 0.87012987, 0.88744589, 0.87012987,\n        0.88744589, 0.87445887, 0.88744589, 0.87878788, 0.88744589,\n        0.83982684, 0.88744589]),\n 'mean_test_score': array([0.86066764, 0.8887931 , 0.85330833, 0.88835834, 0.85287916,\n        0.88749254, 0.85547283, 0.88576093, 0.8533102 , 0.88446223,\n        0.8308087 , 0.88446223]),\n 'std_test_score': array([0.01781692, 0.0019572 , 0.01543788, 0.00266255, 0.01571129,\n        0.00281418, 0.01386174, 0.0044805 , 0.01492659, 0.0055568 ,\n        0.01542481, 0.0055568 ]),\n 'rank_test_score': array([ 7,  1, 10,  2, 11,  3,  8,  4,  9,  5, 12,  5], dtype=int32)}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuned = svm.SVC()\n",
    "parameters = {'kernel':('linear','rbf'),'C':(1,4,8,16,32,64)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameters,cv=10)\n",
    "clf.fit(train_x_vectors,train_propaganda)\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_C</th>\n      <th>param_kernel</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>split5_test_score</th>\n      <th>split6_test_score</th>\n      <th>split7_test_score</th>\n      <th>split8_test_score</th>\n      <th>split9_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.846362</td>\n      <td>0.287889</td>\n      <td>0.076674</td>\n      <td>0.053048</td>\n      <td>1</td>\n      <td>linear</td>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n      <td>0.857759</td>\n      <td>0.857143</td>\n      <td>0.848485</td>\n      <td>0.870130</td>\n      <td>0.839827</td>\n      <td>0.865801</td>\n      <td>0.831169</td>\n      <td>0.861472</td>\n      <td>0.896104</td>\n      <td>0.878788</td>\n      <td>0.860668</td>\n      <td>0.017817</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.490045</td>\n      <td>0.137642</td>\n      <td>0.088266</td>\n      <td>0.002706</td>\n      <td>1</td>\n      <td>rbf</td>\n      <td>{'C': 1, 'kernel': 'rbf'}</td>\n      <td>0.887931</td>\n      <td>0.891775</td>\n      <td>0.891775</td>\n      <td>0.891775</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.888793</td>\n      <td>0.001957</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.911602</td>\n      <td>0.166209</td>\n      <td>0.063874</td>\n      <td>0.011255</td>\n      <td>4</td>\n      <td>linear</td>\n      <td>{'C': 4, 'kernel': 'linear'}</td>\n      <td>0.857759</td>\n      <td>0.839827</td>\n      <td>0.826840</td>\n      <td>0.861472</td>\n      <td>0.844156</td>\n      <td>0.857143</td>\n      <td>0.835498</td>\n      <td>0.861472</td>\n      <td>0.878788</td>\n      <td>0.870130</td>\n      <td>0.853308</td>\n      <td>0.015438</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.895432</td>\n      <td>0.223141</td>\n      <td>0.110377</td>\n      <td>0.025374</td>\n      <td>4</td>\n      <td>rbf</td>\n      <td>{'C': 4, 'kernel': 'rbf'}</td>\n      <td>0.892241</td>\n      <td>0.891775</td>\n      <td>0.887446</td>\n      <td>0.891775</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.883117</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.888358</td>\n      <td>0.002663</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.778479</td>\n      <td>0.330035</td>\n      <td>0.074820</td>\n      <td>0.037225</td>\n      <td>8</td>\n      <td>linear</td>\n      <td>{'C': 8, 'kernel': 'linear'}</td>\n      <td>0.849138</td>\n      <td>0.839827</td>\n      <td>0.826840</td>\n      <td>0.865801</td>\n      <td>0.844156</td>\n      <td>0.857143</td>\n      <td>0.835498</td>\n      <td>0.861472</td>\n      <td>0.878788</td>\n      <td>0.870130</td>\n      <td>0.852879</td>\n      <td>0.015711</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.313404</td>\n      <td>0.086968</td>\n      <td>0.084498</td>\n      <td>0.001728</td>\n      <td>8</td>\n      <td>rbf</td>\n      <td>{'C': 8, 'kernel': 'rbf'}</td>\n      <td>0.892241</td>\n      <td>0.891775</td>\n      <td>0.887446</td>\n      <td>0.883117</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.883117</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.887493</td>\n      <td>0.002814</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.597628</td>\n      <td>0.017413</td>\n      <td>0.049142</td>\n      <td>0.001863</td>\n      <td>16</td>\n      <td>linear</td>\n      <td>{'C': 16, 'kernel': 'linear'}</td>\n      <td>0.857759</td>\n      <td>0.848485</td>\n      <td>0.826840</td>\n      <td>0.861472</td>\n      <td>0.852814</td>\n      <td>0.857143</td>\n      <td>0.839827</td>\n      <td>0.861472</td>\n      <td>0.874459</td>\n      <td>0.874459</td>\n      <td>0.855473</td>\n      <td>0.013862</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.549389</td>\n      <td>0.301787</td>\n      <td>0.094881</td>\n      <td>0.015949</td>\n      <td>16</td>\n      <td>rbf</td>\n      <td>{'C': 16, 'kernel': 'rbf'}</td>\n      <td>0.892241</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.874459</td>\n      <td>0.887446</td>\n      <td>0.883117</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.883117</td>\n      <td>0.887446</td>\n      <td>0.885761</td>\n      <td>0.004481</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.621388</td>\n      <td>0.069331</td>\n      <td>0.058469</td>\n      <td>0.023773</td>\n      <td>32</td>\n      <td>linear</td>\n      <td>{'C': 32, 'kernel': 'linear'}</td>\n      <td>0.853448</td>\n      <td>0.839827</td>\n      <td>0.831169</td>\n      <td>0.861472</td>\n      <td>0.848485</td>\n      <td>0.844156</td>\n      <td>0.844156</td>\n      <td>0.852814</td>\n      <td>0.878788</td>\n      <td>0.878788</td>\n      <td>0.853310</td>\n      <td>0.014927</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.525019</td>\n      <td>0.357026</td>\n      <td>0.116521</td>\n      <td>0.085583</td>\n      <td>32</td>\n      <td>rbf</td>\n      <td>{'C': 32, 'kernel': 'rbf'}</td>\n      <td>0.892241</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.870130</td>\n      <td>0.887446</td>\n      <td>0.883117</td>\n      <td>0.883117</td>\n      <td>0.883117</td>\n      <td>0.883117</td>\n      <td>0.887446</td>\n      <td>0.884462</td>\n      <td>0.005557</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.643429</td>\n      <td>0.127675</td>\n      <td>0.051585</td>\n      <td>0.007817</td>\n      <td>64</td>\n      <td>linear</td>\n      <td>{'C': 64, 'kernel': 'linear'}</td>\n      <td>0.831897</td>\n      <td>0.818182</td>\n      <td>0.826840</td>\n      <td>0.839827</td>\n      <td>0.831169</td>\n      <td>0.805195</td>\n      <td>0.831169</td>\n      <td>0.818182</td>\n      <td>0.865801</td>\n      <td>0.839827</td>\n      <td>0.830809</td>\n      <td>0.015425</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.312031</td>\n      <td>0.102104</td>\n      <td>0.093628</td>\n      <td>0.021163</td>\n      <td>64</td>\n      <td>rbf</td>\n      <td>{'C': 64, 'kernel': 'rbf'}</td>\n      <td>0.892241</td>\n      <td>0.887446</td>\n      <td>0.887446</td>\n      <td>0.870130</td>\n      <td>0.887446</td>\n      <td>0.883117</td>\n      <td>0.883117</td>\n      <td>0.883117</td>\n      <td>0.883117</td>\n      <td>0.887446</td>\n      <td>0.884462</td>\n      <td>0.005557</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n0        0.846362      0.287889         0.076674        0.053048       1   \n1        1.490045      0.137642         0.088266        0.002706       1   \n2        0.911602      0.166209         0.063874        0.011255       4   \n3        1.895432      0.223141         0.110377        0.025374       4   \n4        0.778479      0.330035         0.074820        0.037225       8   \n5        1.313404      0.086968         0.084498        0.001728       8   \n6        0.597628      0.017413         0.049142        0.001863      16   \n7        1.549389      0.301787         0.094881        0.015949      16   \n8        0.621388      0.069331         0.058469        0.023773      32   \n9        1.525019      0.357026         0.116521        0.085583      32   \n10       0.643429      0.127675         0.051585        0.007817      64   \n11       1.312031      0.102104         0.093628        0.021163      64   \n\n   param_kernel                         params  split0_test_score  \\\n0        linear   {'C': 1, 'kernel': 'linear'}           0.857759   \n1           rbf      {'C': 1, 'kernel': 'rbf'}           0.887931   \n2        linear   {'C': 4, 'kernel': 'linear'}           0.857759   \n3           rbf      {'C': 4, 'kernel': 'rbf'}           0.892241   \n4        linear   {'C': 8, 'kernel': 'linear'}           0.849138   \n5           rbf      {'C': 8, 'kernel': 'rbf'}           0.892241   \n6        linear  {'C': 16, 'kernel': 'linear'}           0.857759   \n7           rbf     {'C': 16, 'kernel': 'rbf'}           0.892241   \n8        linear  {'C': 32, 'kernel': 'linear'}           0.853448   \n9           rbf     {'C': 32, 'kernel': 'rbf'}           0.892241   \n10       linear  {'C': 64, 'kernel': 'linear'}           0.831897   \n11          rbf     {'C': 64, 'kernel': 'rbf'}           0.892241   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n0            0.857143           0.848485           0.870130   \n1            0.891775           0.891775           0.891775   \n2            0.839827           0.826840           0.861472   \n3            0.891775           0.887446           0.891775   \n4            0.839827           0.826840           0.865801   \n5            0.891775           0.887446           0.883117   \n6            0.848485           0.826840           0.861472   \n7            0.887446           0.887446           0.874459   \n8            0.839827           0.831169           0.861472   \n9            0.887446           0.887446           0.870130   \n10           0.818182           0.826840           0.839827   \n11           0.887446           0.887446           0.870130   \n\n    split4_test_score  split5_test_score  split6_test_score  \\\n0            0.839827           0.865801           0.831169   \n1            0.887446           0.887446           0.887446   \n2            0.844156           0.857143           0.835498   \n3            0.887446           0.887446           0.883117   \n4            0.844156           0.857143           0.835498   \n5            0.887446           0.887446           0.883117   \n6            0.852814           0.857143           0.839827   \n7            0.887446           0.883117           0.887446   \n8            0.848485           0.844156           0.844156   \n9            0.887446           0.883117           0.883117   \n10           0.831169           0.805195           0.831169   \n11           0.887446           0.883117           0.883117   \n\n    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n0            0.861472           0.896104           0.878788         0.860668   \n1            0.887446           0.887446           0.887446         0.888793   \n2            0.861472           0.878788           0.870130         0.853308   \n3            0.887446           0.887446           0.887446         0.888358   \n4            0.861472           0.878788           0.870130         0.852879   \n5            0.887446           0.887446           0.887446         0.887493   \n6            0.861472           0.874459           0.874459         0.855473   \n7            0.887446           0.883117           0.887446         0.885761   \n8            0.852814           0.878788           0.878788         0.853310   \n9            0.883117           0.883117           0.887446         0.884462   \n10           0.818182           0.865801           0.839827         0.830809   \n11           0.883117           0.883117           0.887446         0.884462   \n\n    std_test_score  rank_test_score  \n0         0.017817                7  \n1         0.001957                1  \n2         0.015438               10  \n3         0.002663                2  \n4         0.015711               11  \n5         0.002814                3  \n6         0.013862                8  \n7         0.004481                4  \n8         0.014927                9  \n9         0.005557                5  \n10        0.015425               12  \n11        0.005557                5  "
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_C</th>\n      <th>param_kernel</th>\n      <th>mean_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>linear</td>\n      <td>0.860668</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>rbf</td>\n      <td>0.888793</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>linear</td>\n      <td>0.853308</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>rbf</td>\n      <td>0.888358</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>linear</td>\n      <td>0.852879</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>rbf</td>\n      <td>0.887493</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>16</td>\n      <td>linear</td>\n      <td>0.855473</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>16</td>\n      <td>rbf</td>\n      <td>0.885761</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>32</td>\n      <td>linear</td>\n      <td>0.853310</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>32</td>\n      <td>rbf</td>\n      <td>0.884462</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>64</td>\n      <td>linear</td>\n      <td>0.830809</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>64</td>\n      <td>rbf</td>\n      <td>0.884462</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   param_C param_kernel  mean_test_score\n0        1       linear         0.860668\n1        1          rbf         0.888793\n2        4       linear         0.853308\n3        4          rbf         0.888358\n4        8       linear         0.852879\n5        8          rbf         0.887493\n6       16       linear         0.855473\n7       16          rbf         0.885761\n8       32       linear         0.853310\n9       32          rbf         0.884462\n10      64       linear         0.830809\n11      64          rbf         0.884462"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 1, 'kernel': 'rbf'}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9193548387096774\n",
      "0.844758064516129\n",
      "0.9173387096774194\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Tree\n",
    "print(clf_dec.score(test_x_vectors,test_propaganda))\n",
    "# For Logistic Regression\n",
    "print(clf_log.score(test_x_vectors,test_propaganda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28571429 0.16       0.94462541]\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(test_propaganda,clf_svm.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEUTRAL,Propaganda.NEGATIVE]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python382jvsc74a57bd0082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}