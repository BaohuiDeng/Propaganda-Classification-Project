{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers requests beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 1135, 1108, 1363, 1133, 1180, 2707, 1151, 1618,  119, 2038,  102])\n",
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0134,  0.0757]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode('It was good but couldve been better. Great', return_tensors='pt')\n",
    "print(tokens[0])\n",
    "result = model(tokens)\n",
    "print(result)\n",
    "result.logits\n",
    "print(int(torch.argmax(result.logits))+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: Predefined CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Propaganda:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,sentence,SUBJprop):\n",
    "        self.sentence = sentence\n",
    "        self.SUBJprop = SUBJprop\n",
    "        self.propaganda = self.get_propaganda()        \n",
    "\n",
    "    def get_propaganda(self):\n",
    "        if int(self.SUBJprop) <=3 :\n",
    "            return Propaganda.NEGATIVE\n",
    "        else:\n",
    "            return Propaganda.POSITIVE\n",
    "\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_sentence(self):\n",
    "        return [x.sentence for x  in self.reviews]\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        return [x.propaganda for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, self.reviews))\n",
    "        negative_shrunk = negative[:len(positive)]\n",
    "        self.reviews = positive + negative_shrunk\n",
    "        random.shuffle(self.reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows:\n",
      "16774\n",
      "Total Positive:\n",
      "3780\n",
      "Total Negative:\n",
      "12994\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Review' object has no attribute 'getSUBJprop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-786343624f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Negative:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropaganda\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPropaganda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEGATIVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSUBJprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m# sentenceArray = [ x.sentence for x  in reviews]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Review' object has no attribute 'getSUBJprop'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('Data/finalDataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "\n",
    "\n",
    "print(\"Total Rows:\")\n",
    "print(len(reviews))\n",
    "print(\"Total Positive:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))))\n",
    "print(\"Total Negative:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))))\n",
    "#print(reviews[0].getSUBJprop)\n",
    "# sentenceArray = [ x.sentence for x  in reviews] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to use the bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def propaganda_score(review_sentence):\n",
    "    tokens = tokenizer.encode(review_sentence, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Prep Data (split into train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train:\n",
      "11741\n",
      "Positive:\n",
      "2646\n",
      "Negative:\n",
      "9095\n",
      "\n",
      "Total Development:\n",
      "2516\n",
      "Positive:\n",
      "567\n",
      "Negative:\n",
      "1949\n",
      "\n",
      "Total Test:\n",
      "2517\n",
      "Positive:\n",
      "567\n",
      "Negative:\n",
      "1950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "neg_prop = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))\n",
    "pos_prop = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))\n",
    "\n",
    "########################################################################################\n",
    "#split trainig and DevTest dataset\n",
    "neg_train, neg_devtest  = train_test_split(neg_prop , train_size=0.7, random_state = 42 )\n",
    "pos_train, pos_devtest = train_test_split(pos_prop , train_size=0.7, random_state = 42 )\n",
    "########################################################################################\n",
    "#prepare training dataset\n",
    "train = neg_train + pos_train\n",
    "random.shuffle(train)\n",
    "########################################################################################\n",
    "#prepare development and test dataset\n",
    "neg_dev, neg_test = train_test_split(neg_devtest , train_size=0.5, random_state = 42 )\n",
    "pos_dev, pos_test = train_test_split(pos_devtest , train_size=0.5, random_state = 42 )\n",
    "\n",
    "dev = neg_dev + pos_dev\n",
    "random.shuffle(dev)\n",
    "\n",
    "test = neg_test + pos_test\n",
    "random.shuffle(test)\n",
    "########################################################################################\n",
    "print(\"Total Train:\")\n",
    "print(len(train))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_train))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_train))\n",
    "\n",
    "print(\"\\nTotal Development:\")\n",
    "print(len(dev))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_dev))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_dev))\n",
    "\n",
    "print(\"\\nTotal Test:\")\n",
    "print(len(test))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_test))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: Seperate the attribute, originally our array has text and score. we want them to be a seperate array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_container = ReviewContainer(train)\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "train_sentence = train_container.get_sentence()   \n",
    "train_propaganda = train_container.get_propaganda() \n",
    "\n",
    "development_sentence = [x.sentence for x in dev]\n",
    "development_propaganda = [x.propaganda for x in dev]\n",
    "\n",
    "test_sentence = [x.sentence for x in test]\n",
    "test_propaganda = [x.propaganda for x in test]\n",
    "\n",
    "\n",
    "# print(\"Toalt rows after balance training dataset:\")\n",
    "# print(len(train_sentence))\n",
    "\n",
    "# print(\"Positive Propaganda:\")\n",
    "# print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "# print(\"Negative Propaganda:\")\n",
    "# print(train_propaganda.count(Propaganda.NEGATIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Solemnly professed:</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ford can’t remember where and when the alleged...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Perhaps, I don’t know.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The concerns, which the department says can be...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The length of their prison terms, in part, fue...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5287</th>\n      <td>-1.8% Employed 22,125 22,216 91 0.4% Employmen...</td>\n    </tr>\n    <tr>\n      <th>5288</th>\n      <td>Fillmore, Pierce, Buchanan?</td>\n    </tr>\n    <tr>\n      <th>5289</th>\n      <td>From there, Murillo continues writing for anot...</td>\n    </tr>\n    <tr>\n      <th>5290</th>\n      <td>So much for “I am woman, hear me roar.”</td>\n    </tr>\n    <tr>\n      <th>5291</th>\n      <td>The immigrant unemployment rate fell by 0.2 po...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5292 rows × 1 columns</p>\n</div>",
      "text/plain": "                                               sentence\n0                                   Solemnly professed:\n1     Ford can’t remember where and when the alleged...\n2                                Perhaps, I don’t know.\n3     The concerns, which the department says can be...\n4     The length of their prison terms, in part, fue...\n...                                                 ...\n5287  -1.8% Employed 22,125 22,216 91 0.4% Employmen...\n5288                        Fillmore, Pierce, Buchanan?\n5289  From there, Murillo continues writing for anot...\n5290            So much for “I am woman, hear me roar.”\n5291  The immigrant unemployment rate fell by 0.2 po...\n\n[5292 rows x 1 columns]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = np.random.normal(size=100)  \n",
    "e_dataframe = pd.DataFrame(train_sentence)      \n",
    "e_dataframe.rename(index=str, columns={0:'sentence'})\n",
    "#data= e_dataframe['sentence'].apply(lambda x: propaganda_score(x[:512]))\n",
    "#print(data)\n",
    "# propaganda_score(train_sentence[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7227 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (7227) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-31864948aea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresultScore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_sentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresultScore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpropaganda_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultScore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1f69bc57e837>\u001b[0m in \u001b[0;36mpropaganda_score\u001b[0;34m(review_sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpropaganda_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1503\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7227) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# resultScore=[]\n",
    "# for x in train_sentence:\n",
    "#     resultScore.append(propaganda_score(x))\n",
    "# print(resultScore[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold cross validation\n",
    "# Basic example (MORE INFO)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf=KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(train_sentence):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#StratifiedKFold is better when we have unbalanced data, it makes sure that in training there is sufficient for the smallest class\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# KFold cross validation - on our dataset\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=2)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_nb = []\n",
    "\n",
    "# passong training dataset to Cross Validation\n",
    "Sample_Array_sentence = train_sentence\n",
    "Sample_Array_propaganda = train_propaganda\n",
    "\n",
    "\n",
    "# Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "Sample_Array_sentence_vectors = vectorizer.fit_transform(Sample_Array_sentence)\n",
    "\n",
    "\n",
    "for train_index, test_index in folds.split(Sample_Array_sentence_vectors,Sample_Array_propaganda):\n",
    "    X_train, X_test, y_train, y_test = Sample_Array_sentence_vectors[train_index], Sample_Array_sentence_vectors[test_index], \\\n",
    "                                       Sample_Array_propaganda[train_index], Sample_Array_propaganda[test_index]\n",
    "\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X_train, X_test, y_train, y_test))  \n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))\n",
    "    scores_nb.append(get_score(GaussianNB(), X_train.toarray(), X_test.toarray(), y_train, y_test))\n",
    "\n",
    "\n",
    "print(\"Score of Logistic Regression\")\n",
    "print(scores_logistic)\n",
    "print(\"Score of SVM\")\n",
    "print(scores_svm)\n",
    "print(\"Score of RandomForest\")\n",
    "print(scores_rf)\n",
    "print(\"Score of Naive Bayes\")\n",
    "print(scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same what we have done before but with the Sklearn Package\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "# cross_val_score(SVC(gamma='auto'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "# cross_val_score(RandomForestClassifier(n_estimators=40),Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_sentence) # return a matrix of either 0 or 1 # train_x is our text\n",
    "test_x_vectors = vectorizer.transform(test_sentence)\n",
    "underthreshold_x_vectors = vectorizer.transform(UnderThreshold)\n",
    "\n",
    "# Todo:\n",
    "# transform development set to vectors\n",
    "development_x_vectors = vectorizer.fit_transform(development_sentence)\n",
    "print(train_sentence[0])\n",
    "print(train_x_vectors[2517].toarray())\n",
    "print(len(train_x_vectors.toarray()))\n",
    "\n",
    "print(test_x_vectors[0].toarray())\n",
    "print(len(test_x_vectors.toarray()))\n",
    "\n",
    "print(development_x_vectors[0].toarray())\n",
    "print(len(development_x_vectors.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf',C=1, probability=True)\n",
    "clf_svm.fit(train_x_vectors, train_propaganda)\n",
    "clf_svm.predict(test_x_vectors[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray() , train_propaganda)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_log.predict(test_x_vectors[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIP : Predict_Proba using Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMProbabilityPropaganda=[]\n",
    "UnderThreshold = [] \n",
    "UnderThresholdProp = []\n",
    "\n",
    "\n",
    "for i in range(len(test_x_vectors.toarray())):\n",
    "  # check the dpositive propaganas\n",
    "  if(clf_svm.predict_proba(test_x_vectors[i])[0][1]) < 0.60:\n",
    "    # check the negative propagandas\n",
    "    if(clf_svm.predict_proba(test_x_vectors[i])[0][0]) < 0.60:\n",
    "      UnderThreshold.append(test_sentence[i])\n",
    "      UnderThresholdProp.append(test_propaganda[i])\n",
    "\n",
    "\n",
    "\n",
    "print(len(UnderThreshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second model Logistic regression\n",
    "SecondUnderThreshold = [] \n",
    "SecondUnderThresholdProp = []\n",
    "\n",
    "for j in range(len(UnderThreshold)):\n",
    "  # check the dpositive propaganas\n",
    "  if(clf_log.predict_proba(underthreshold_x_vectors[j])[0][1]) < 0.60:\n",
    "    # check the negative propagandas\n",
    "    if(clf_log.predict_proba(underthreshold_x_vectors[j])[0][0]) < 0.60:\n",
    "      SecondUnderThreshold.append(UnderThreshold[j])\n",
    "      SecondUnderThresholdProp.append(UnderThresholdProp[j])\n",
    "\n",
    "# bag of words\n",
    "SecondUnderThreshold_x_vectors = vectorizer.transform(SecondUnderThreshold)\n",
    "\n",
    "\n",
    "print(len(SecondUnderThreshold))\n",
    "# print(clf_log.predict(underthreshold_x_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to know how previous step works\n",
    "# test=clf_log.predict_proba(test_x_vectors[0])\n",
    "# print(test)\n",
    "# print(test[0])\n",
    "# print(test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Accuracy\n",
    "# For Support Vector Machine\n",
    "print(clf_svm.score(underthreshold_x_vectors,UnderThresholdProp))\n",
    "print(type(test_x_vectors))\n",
    "print(type(UnderThreshold))\n",
    "# For Decision Tree\n",
    "# print(clf_dec.score(test_x_vectors,test_propaganda))\n",
    "# # For Decision Naive Bayes\n",
    "# print(clf_gnb.score(test_x_vectors.toarray(),test_propaganda))\n",
    "# # For Logistic Regression\n",
    "# print(clf_log.score(test_x_vectors,test_propaganda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(UnderThresholdProp, clf_svm.predict(underthreshold_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels\n",
    "\n",
    "# # For Support Decision Tree\n",
    "# print(f1_score(UnderThresholdProp,clf_dec.predict(UnderThreshold),average = None, \n",
    "# labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# # For Support Naive Bayes\n",
    "# print(f1_score(UnderThresholdProp,clf_gnb.predict(UnderThreshold.toarray()),average = None, \n",
    "# labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# # For Logistic Regression\n",
    "# print(f1_score(UnderThresholdProp,clf_log.predict(UnderThreshold),average = None, \n",
    "# labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(test_propaganda, clf_svm.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels\n",
    "\n",
    "# # For Support Decision Tree\n",
    "# print(f1_score(test_propaganda,clf_dec.predict(test_x_vectors),average = None, \n",
    "# labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# # For Support Naive Bayes\n",
    "# print(f1_score(test_propaganda,clf_gnb.predict(test_x_vectors.toarray()),average = None, \n",
    "# labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# # For Logistic Regression\n",
    "# print(f1_score(test_propaganda,clf_log.predict(test_x_vectors),average = None, \n",
    "# labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(precision_score(UnderThresholdProp, clf_svm.predict(underthreshold_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(recall_score(UnderThresholdProp, clf_svm.predict(underthreshold_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# check number of positive and negative classes in training set\n",
    "print(\"Number of NEGATIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n",
    "print(\"Number of POSITIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "\n",
    "# check number of positive and negative classes in test set\n",
    "y = np.array(test_propaganda)\n",
    "number_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "number_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in test set:\")\n",
    "print(number_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in test set:\")\n",
    "print(number_of_POSITIVE)\n",
    "\n",
    "# check number of positive and negative classes in development set\n",
    "\n",
    "y = np.array(development_propaganda)\n",
    "Dnumber_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "Dnumber_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in development set:\")\n",
    "print(Dnumber_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in development set:\")\n",
    "print(Dnumber_of_POSITIVE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 7: Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuned = svm.SVC()\n",
    "parameters = {'kernel':('linear','rbf'),'C':(1,4,8,16,32,64)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameters,cv=10)\n",
    "clf.fit(train_x_vectors,train_propaganda)\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8')",
   "name": "python382jvsc74a57bd0082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}