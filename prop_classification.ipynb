{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: Predefined CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Propaganda:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,sentence,SUBJprop):\n",
    "        self.sentence = sentence\n",
    "        self.SUBJprop = SUBJprop\n",
    "        self.propaganda = self.get_propaganda()        \n",
    "\n",
    "    def get_propaganda(self):\n",
    "        if int(self.SUBJprop) <=3 :\n",
    "            return Propaganda.NEGATIVE\n",
    "        else:\n",
    "            return Propaganda.POSITIVE\n",
    "\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_sentence(self):\n",
    "        return [x.sentence for x  in self.reviews]\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        return [x.propaganda for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, self.reviews))\n",
    "        negative_shrunk = negative[:len(positive)]\n",
    "        self.reviews = positive + negative_shrunk\n",
    "        random.shuffle(self.reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Rows:\n16774\nTotal Positive:\n3780\nTotal Negative:\n12994\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('Data/finalDataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "\n",
    "\n",
    "print(\"Total Rows:\")\n",
    "print(len(reviews))\n",
    "print(\"Total Positive:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))))\n",
    "print(\"Total Negative:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))))\n",
    "\n",
    "# print(reviews[0].getSUBJprop)\n",
    "# sentenceArray = [ x.sentence for x  in reviews] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Prep Data (split into train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Train:\n11741\nPositive:\n2646\nNegative:\n9095\n\nTotal Development:\n2516\nPositive:\n567\nNegative:\n1949\n\nTotal Test:\n2517\nPositive:\n567\nNegative:\n1950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "neg_prop = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))\n",
    "pos_prop = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))\n",
    "\n",
    "########################################################################################\n",
    "#split trainig and DevTest dataset\n",
    "neg_train, neg_devtest  = train_test_split(neg_prop , train_size=0.7, random_state = 42 )\n",
    "pos_train, pos_devtest = train_test_split(pos_prop , train_size=0.7, random_state = 42 )\n",
    "########################################################################################\n",
    "#prepare training dataset\n",
    "train = neg_train + pos_train\n",
    "random.shuffle(train)\n",
    "########################################################################################\n",
    "#prepare development and test dataset\n",
    "neg_dev, neg_test = train_test_split(neg_devtest , train_size=0.5, random_state = 42 )\n",
    "pos_dev, pos_test = train_test_split(pos_devtest , train_size=0.5, random_state = 42 )\n",
    "\n",
    "dev = neg_dev + pos_dev\n",
    "random.shuffle(dev)\n",
    "\n",
    "test = neg_test + pos_test\n",
    "random.shuffle(test)\n",
    "########################################################################################\n",
    "print(\"Total Train:\")\n",
    "print(len(train))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_train))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_train))\n",
    "\n",
    "print(\"\\nTotal Development:\")\n",
    "print(len(dev))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_dev))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_dev))\n",
    "\n",
    "print(\"\\nTotal Test:\")\n",
    "print(len(test))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_test))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: Seperate the attribute, originally our array has text and score. we want them to be a seperate array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Toalt rows after balance training dataset:\n5292\nPositive Propaganda:\n2646\nNegative Propaganda:\n2646\n"
     ]
    }
   ],
   "source": [
    "train_container = ReviewContainer(train)\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "train_sentence = train_container.get_sentence()   \n",
    "train_propaganda = train_container.get_propaganda() \n",
    "\n",
    "development_sentence = [x.sentence for x in dev]\n",
    "development_propaganda = [x.propaganda for x in dev]\n",
    "\n",
    "test_sentence = [x.sentence for x in test]\n",
    "test_propaganda = [x.propaganda for x in test]\n",
    "\n",
    "print(\"Toalt rows after balance training dataset:\")\n",
    "print(len(train_sentence))\n",
    "\n",
    "print(\"Positive Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "print(\"Negative Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))"
   ]
  },
  {
   "source": [
    "# Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1764 1765 1766 ... 5289 5290 5291] [   0    1    2 ... 1761 1762 1763]\n[   0    1    2 ... 5289 5290 5291] [1764 1765 1766 ... 3525 3526 3527]\n[   0    1    2 ... 3525 3526 3527] [3528 3529 3530 ... 5289 5290 5291]\n"
     ]
    }
   ],
   "source": [
    "# KFold cross validation\n",
    "# Basic example (MORE INFO)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf=KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(train_sentence):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#StratifiedKFold is better when we have unbalanced data, it makes sure that in training there is sufficient for the smallest class\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# KFold cross validation - on our dataset\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=2)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_nb = []\n",
    "\n",
    "# passong training dataset to Cross Validation\n",
    "Sample_Array_sentence = train_sentence\n",
    "Sample_Array_propaganda = train_propaganda\n",
    "\n",
    "\n",
    "# Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "Sample_Array_sentence_vectors = vectorizer.fit_transform(Sample_Array_sentence)\n",
    "\n",
    "\n",
    "for train_index, test_index in folds.split(Sample_Array_sentence_vectors,Sample_Array_propaganda):\n",
    "    X_train, X_test, y_train, y_test = Sample_Array_sentence_vectors[train_index], Sample_Array_sentence_vectors[test_index], \\\n",
    "                                       Sample_Array_propaganda[train_index], Sample_Array_propaganda[test_index]\n",
    "\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X_train, X_test, y_train, y_test))  \n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))\n",
    "    scores_nb.append(get_score(GaussianNB(), X_train.toarray(), X_test.toarray(), y_train, y_test))\n",
    "\n",
    "\n",
    "print(\"Score of Logistic Regression\")\n",
    "print(scores_logistic)\n",
    "print(\"Score of SVM\")\n",
    "print(scores_svm)\n",
    "print(\"Score of RandomForest\")\n",
    "print(scores_rf)\n",
    "print(\"Score of Naive Bayes\")\n",
    "print(scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same what we have done before but with the Sklearn Package\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "# cross_val_score(SVC(gamma='auto'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "# cross_val_score(RandomForestClassifier(n_estimators=40),Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "As I write this, the outrage is doing the opposite of dying down, and is surely a sign of how fed up Catholics – even those who would never identify themselves as Traditionalists – have become with this pope and his cadre of episcopal bullies.\n[[0 0 0 ... 0 0 0]]\n5292\n[[0 0 0 ... 0 0 0]]\n2517\n[[0 0 0 ... 0 0 0]]\n2516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_sentence) # return a matrix of either 0 or 1 # train_x is our text\n",
    "test_x_vectors = vectorizer.transform(test_sentence)\n",
    "\n",
    "# Todo:\n",
    "# transform development set to vectors\n",
    "development_x_vectors = vectorizer.fit_transform(development_sentence)\n",
    "print(train_sentence[0])\n",
    "print(train_x_vectors[2517].toarray())\n",
    "print(len(train_x_vectors.toarray()))\n",
    "\n",
    "print(test_x_vectors[0].toarray())\n",
    "print(len(test_x_vectors.toarray()))\n",
    "\n",
    "print(development_x_vectors[0].toarray())\n",
    "print(len(development_x_vectors.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf',C=1, probability=True)\n",
    "clf_svm.fit(train_x_vectors, train_propaganda)\n",
    "clf_svm.predict(test_x_vectors[1])\n",
    "\n",
    "# SVMProbabilityPropaganda=[]\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# while i < len(development_x_vectors.toarray()):\n",
    "#   SVMProbabilityPropaganda.append(clf_svm.predict_proba(development_x_vectors[i]))\n",
    "#   i += 1\n",
    "# IndexError: row index (2517) out of range\n",
    "\n",
    "# SVMProbabilityPropaganda.append(clf_svm.predict_proba(test_x_vectors[0]))\n",
    "\n",
    "\n",
    "# print('the first item in array')\n",
    "# print(SVMProbabilityPropaganda[0])\n",
    "# print('the whole Array')\n",
    "# print(SVMProbabilityPropaganda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(SVMProbabilityPropaganda[0])\n",
    "# print(SVMProbabilityPropaganda[0][0])\n",
    "# print(SVMProbabilityPropaganda[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray() , train_propaganda)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tanna\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_log.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4819229241160111\n",
      "0.5311879221295193\n",
      "0.4489471593166468\n",
      "0.5554231227651967\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "# For Support Vector Machine\n",
    "print(clf_svm.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Tree\n",
    "print(clf_dec.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Naive Bayes\n",
    "print(clf_gnb.score(test_x_vectors.toarray(),test_propaganda))\n",
    "# For Logistic Regression\n",
    "print(clf_log.score(test_x_vectors,test_propaganda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.36015702 0.564753  ]\n",
      "[0.34225195 0.63580247]\n",
      "[0.37997318 0.50411155]\n",
      "[0.37099494 0.6562212 ]\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(test_propaganda, clf_svm.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels\n",
    "\n",
    "# For Support Decision Tree\n",
    "print(f1_score(test_propaganda,clf_dec.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Support Naive Bayes\n",
    "print(f1_score(test_propaganda,clf_gnb.predict(test_x_vectors.toarray()),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Logistic Regression\n",
    "print(f1_score(test_propaganda,clf_log.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of NEGATIVE in training set:\n2646\nNumber of POSITIVE in training set:\n2646\n\nNumber of NEGATIVE in test set:\n1950\nNumber of POSITIVE in test set:\n567\n\nNumber of NEGATIVE in development set:\n1949\nNumber of POSITIVE in development set:\n567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# check number of positive and negative classes in training set\n",
    "print(\"Number of NEGATIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n",
    "print(\"Number of POSITIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "\n",
    "# check number of positive and negative classes in test set\n",
    "y = np.array(test_propaganda)\n",
    "number_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "number_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in test set:\")\n",
    "print(number_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in test set:\")\n",
    "print(number_of_POSITIVE)\n",
    "\n",
    "# check number of positive and negative classes in development set\n",
    "\n",
    "y = np.array(development_propaganda)\n",
    "Dnumber_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "Dnumber_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in development set:\")\n",
    "print(Dnumber_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in development set:\")\n",
    "print(Dnumber_of_POSITIVE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 7: Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuned = svm.SVC()\n",
    "parameters = {'kernel':('linear','rbf'),'C':(1,4,8,16,32,64)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameters,cv=10)\n",
    "clf.fit(train_x_vectors,train_propaganda)\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0cafe0eb33a5b748aef708b3398fce0f2e899e1701441dfed3bd3048456ea6d64",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 3,
  "metadata": {
   "interpreter": {
    "hash": "030fe2e537001a0f06a091970833f1c1ec5f59e52d4488afbdc2cc8dde6768f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}