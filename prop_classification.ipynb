{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: Predefined CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Propaganda:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,sentence,SUBJprop):\n",
    "        self.sentence = sentence\n",
    "        self.SUBJprop = SUBJprop\n",
    "        self.propaganda = self.get_propaganda()\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        if int(self.SUBJprop) <=3:\n",
    "            return Propaganda.NEGATIVE\n",
    "        else:\n",
    "            return Propaganda.POSITIVE\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self,rewievs):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_sentence(self):\n",
    "        return [x.sentence for x  in self.reviews]\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        return [x.propaganda for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, self.reviews))\n",
    "        negative_shrunk = negative[:len(positive)]\n",
    "        self.reviews = positive + negative_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "miley and liam fighting false rumors swirl that theyre in a feud over a supposed prenup\n1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('Data/finalDataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "\n",
    "print(reviews[0].sentence)\n",
    "print(reviews[0].SUBJprop)\n",
    "sentenceArray = [ x.sentence for x  in reviews] \n",
    "# print(sentenceArray[2])\n",
    "\n",
    "# remove number\n",
    "s= sentenceArray[0]\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "    # translate(remove_digits)\n",
    "sentenceArray_num = [x.translate(remove_digits) for x in sentenceArray]\n",
    "#print(sentenceArray_num[3])\n",
    "\n",
    "# remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "# s = 'string with \"punctuation\" inside of it! Does this work? I hope so.'\n",
    "# print(s.translate(translator))\n",
    "sentenceArray_pun = [x.translate(translator) for x in sentenceArray]\n",
    "#print(sentenceArray_pun[0])\n",
    "\n",
    "# remove white space\n",
    "input_str = \" \\t a string example\\t \"\n",
    "input_str = input_str.strip()\n",
    "#print(input_str)\n",
    "sentenceArray_white = [x.strip() for x in sentenceArray]\n",
    "#print(sentenceArray_white[4])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['are', 'miley', 'cyrus', 'and', 'liam', 'hemsworth', 'fighting']\n",
      "#######################################################################################\n",
      "['are miley cyrus and liam hemsworth fighting']\n"
     ]
    }
   ],
   "source": [
    "# word tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_docs = [word_tokenize(doc) for doc in sentenceArray]\n",
    "\n",
    "print(tokenized_docs[1])\n",
    "print(\"#######################################################################################\")\n",
    "\n",
    "#Sentence tokenization\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_token = [sent_tokenize(doc) for doc in sentenceArray]\n",
    "print(sent_token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ", 'Privacy', 'Policy', 'Terms', 'Use', '.'], ['The', 'aides', 'named', 'Imran', 'Awan', ',', 'wife', 'Hina', 'Alvi', ',', 'brothers', 'Abid', 'Jamal', ',', 'friend', 'Rao', 'Abbas', ',', 'Pakistani-born', 'aides', '.'], ['And', 'father', 'Muslim', 'spy', 'ring', 'Imran', 'Awan', 'transferred', 'USB', 'drive', 'Pakistani', 'senator', 'former', 'head', 'Pakistani', 'intelligence', 'agency', '.'], ['Capitol', 'Police', 'looking', 'massive', 'amounts', 'data', 'Awans', 'reportedly', 'downloaded', 'congressional', 'system', ',', 'thousands', 'illegal', 'logins', 'made', 'official', 'system', ',', 'possible', 'theft', 'tens', 'thousands', 'dollars', 'congressional', 'equipment', 'fraud', 'sent', 'foreign', 'governments', 'groups', '.'], ['No', 'wonder', 'Democrats', 'tried', 'squirrel', 'jihad', 'spies', 'country', '.'], ['Congress', 'must', 'investigate', 'act', '.'], ['“', 'Witness', 'Said', 'Awan', 'Wiretapped', 'Her', ',', 'Then', 'Bank', 'Account', 'She', 'Controlled', 'Was', 'Drained', ',', '”', 'Luke', 'Rosiak', ',', 'Daily', 'Caller', 'News', 'Foundation', ',', 'May', '21', ',', '2018', '(', 'thanks', 'Todd', ')', ':'], ['After', 'former', 'Democratic', 'IT', 'aide', 'Imran', 'Awan', 'allegedly', 'threatened', 'stepmother', 'talk', 'police', ',', 'email', 'account', 'accessed', 'suspicious', 'ways', 'lawyer', 'one', 'Awan', '’', 'brothers', 'found', 'emailed', 'FBI', 'specific', 'dates', 'lashed', ':', '“', 'You', '’', 'liar', ',', '’', '?', '”', 'Days', ',', 'bank', 'account', 'stepmother', 'controlled', 'almost', 'completely', 'drained', 'payment', 'Imran', '’', 'brother', ',', 'Abid', 'Awan', ',', 'bank', 'records', 'show', '—', 'said', 'afraid', 'press', 'criminal', 'charges', 'claims', 'threatened', '.'], ['The', 'stepmother', ',', 'Samina', 'Gilani', ',', 'also', 'previously', 'said', 'Imran', 'stole', 'two', 'laptops', '.'], ['Imran', ',', 'Abid', 'Jamal', 'Awan', '—', 'along', 'Imran', '’', 'wife', ',', 'Hina', 'Alvi', ',', 'friend', '—', 'worked', 'IT', 'administrators', '1', 'every', '5', 'House', 'Democrats', 'could', 'read', 'emails', 'files', 'police', 'banned', 'network', 'February', '2017for', '“', 'numerous', 'violations', 'House', 'security', 'policies.', '”', 'Months', 'later', ',', 'none', 'family', 'jail', ',', 'stepmother', 'witnesses', 'said', 'Imran', 'Abid', 'used', 'freedom', 'try', 'steer', 'outcome', 'case', 'since', ',', 'including', 'threatening', 'cooperate', 'authorities', ',', 'TheDCNF', 'previously', 'reported', '.'], ['In', 'April', '2016', ',', 'House', '’', 'Chief', 'Administrative', 'Officer', '(', 'CAO', ')', 'detected', 'allegedly', 'falsified', 'purchase', 'orders', ',', 'Inspector', 'General', 'quickly', 'expanded', 'scope', 'investigate', 'cyber', 'violations', ',', 'finding', 'members', 'Awan', 'family', 'improperly', 'accessed', 'congressmen', '’', 'servers', 'House', 'Democratic', 'Caucus', 'server', 'thousands', 'times', '.'], ['Though', 'House', 'officials', 'suspected', 'equipment', 'stolen', ',', 'Capitol', 'Police', 'search', 'homes', ',', 'The', 'Daily', 'Caller', 'News', 'Foundation', 'learned', ',', 'ban', 'network', 'nearly', 'year', 'later', '.'], ['In', 'meantime', ',', 'evidence', 'appears', 'compromised', ':', 'In', 'December', '2016', ',', 'CAO', 'notified', 'congressmen', 'caucus', 'server', 'physically', 'disappeared', '.'], ['Though', 'Abid', 'played', 'prominent', 'role', 'late-2016', 'IG', 'report', ',', 'arrested', ',', 'congressmen', 'saying', 'criminal', 'investigation', 'ongoing', '.'], ['In', 'January', '2017', ',', 'days', 'around', 'father', '’', 'death', ',', 'Abid', 'removed', 'Gilani', 'beneficiary', 'father', '’', 'life', 'insurance', 'replaced', ',', 'led', 'lawsuit', ',', 'TheDCNF', 'previously', 'reported', '.'], ['Abid', '’', 'attorney', ',', 'Jim', 'Bacon', ',', 'used', 'life', 'insurance', 'lawsuit', 'force', 'Gilani', 'sit', 'sworn', 'deposition', 'Oct.', '4', ',', '2017', 'told', 'reveal', 'told', 'FBI', 'congressional', 'criminal', 'probe', 'tried', 'get', 'find', 'details', 'investigators', '.'], ['In', 'one', 'exchange', ',', 'Bacon', 'knew', 'emailed', 'FBI', '.'], ['BACON', 'Q', ':', '[', 'redacted', ']', 'email', 'address', ',', '’', '?'], ['And', 'send', 'emails', 'address', 'including', 'two', 'emails', 'FBI', ',', '’', '?'], ['GILANI', 'A', ':', 'Yes', ',', 'long', 'time', 'ago', '.'], ['Q', ':', 'No', ',', 'long', 'time', 'ago', '.'], ['March', '5th', ',', '2017', '.'], ['March', '6th', ',', '2017', '.'], ['Ma', '’', ',', 'lied', ',', '’', '?'], ['You', 'lied', ',', '’', '?'], ['You', '’', 'liar', ',', '’', '?'], ['A', ':', 'I', 'forgot', '.'], ['It', 'mind', '.'], ['BACON', ':', 'Ah', '.'], ['I', 'think', 'need', 'take', 'break', 'I', 'explode', '.'], ['Bacon', 'respond', 'questions', 'TheDCNF', 'knew', 'Gilani', 'emailed', 'FBI', 'dates…', '.'], ['Article', 'posted', 'permission', 'Pamela', 'Geller'], ['Pamela', 'Geller', \"'s\", 'commitment', 'freedom', 'jihad', 'Shariah', 'shines', 'forth', 'books'], ['PROOF', ':', 'The', 'LVMPD', 'And', 'FBI', 'Failed', 'To', 'Catalog', 'At', 'Least', 'One', 'Deceased', 'Las', 'Vegas', 'Massacre', 'Victim', 'As', 'Death', 'Toll', 'Rises'], ['In', 'described', 'gross', 'negligence', 'massive', 'cover-up', 'truth', ',', 'F.B.I', '.'], ['LVMPD', 'failed', 'record', 'death', 'least', 'one', 'shooting', 'victim', 'killed', 'massacre'], ['LAS', 'VEGAS', '(', 'INTELLIHUB', ')', '—', 'The', 'Las', 'Vegas', 'Metropolitan', 'Police', 'Department', 'Federal', 'Bureau', 'Investigation', 'failed', 'catalogue', 'least', 'one', 'deceased', 'victim', '1', 'October', 'massacre', 'reportedly', 'left', '58', 'people', 'dead', '.'], ['The', '59th', 'victim', ',', 'currently', 'unnamed', 'completely', 'botched', 'investigation', 'cover-up', ',', 'shot', 'killed', 'parking', 'lot', 'nearby', 'business', 'attack', '.'], ['The', 'woman', '’', 'lifeless', 'body', 'seen', 'drug', 'across', 'parking', 'lot', 'several', 'men', 'placed', 'body', 'behind', 'pick-up', 'truck', 'gunfire', 'continued', '.'], ['The', 'event', 'reported', 'Intellihub', '’', 'Shepard', 'Ambellas', 'Nov.', '11', ',', '2017', ',', 'article', 'titled', 'Private', 'surveillance', 'footage', 'reveals', '“', 'helicopter', 'hovering', 'overhead', '”', 'time', 'Las', 'Vegas', 'Massacre', ',', 'FBI', 'never', 'asked', 'tape', ',', 'excerpt', 'footage', 'aired', 'Tucker', 'Carlson', 'Tonight', '.'], ['At', '10:16', 'p.m.', ',', 'two', 'men', 'drag', '“', 'fallen', 'victim', '”', 'across', 'parking', 'lot', '.'], ['The', 'men', 'position', 'victim', 'behind', 'Ford', 'pickup', 'truck', ',', 'presumably', 'shield', 'victim', 'taking', 'incoming', 'rounds', 'attempted', 'give', 'victim', 'medical', 'assistance', '.'], ['“', 'Later', 'ten-twenty-four', 'p.m.', ',', 'one', 'men', 'places', 'shirt', 'across', 'victim', '’', 'face', 'ten-thirty-two', 'man', 'places', 'appears', 'blanket', 'towel', 'body', 'given', 'hope', ',', '”', 'Tucker', 'Carlson', 'said', '.'], ['“', 'Police', 'arrive', 'area', 'first', 'time', 'around', 'ten-forty-five', 'p.m.', 'body', 'still', 'there.', '”', 'The', 'victim', '’', 'body', 'eventually', 'loaded', 'back', 'Ford', 'Raptor', 'pickup', 'truck', '11:50', 'p.m.', 'taken', 'away', '.'], ['Astonishingly', ',', 'times', '10:13', 'p.m.', '10:16', 'p.m.', 'good', 'amount', 'debris', 'seen', 'pushed', 'downward', 'sideways', 'front', 'camera', 'Carlson', 'claims', '“', 'helicopter', 'hovering', 'overhead.', '”', 'A', 'quick', 'review', 'flight', 'records', 'time', 'reveals', 'squadron', 'EC-130', 'Eurocopters', 'departed', 'Maverick', 'Leasing', 'LLC', '10:12', 'p.m.', ',', 'several', 'appear', 'overflown', 'parking', 'lot', 'victim', 'debris', 'seen', '.'], ['However', ',', 'departure', 'choppers', 'fact', 'several', 'overflew', 'parking', 'lot', 'explain', 'debris', 'kicked', 'heavy', 'downdraft', ',', 'prop', 'wash', ',', 'possibly', 'helicopter', 'hovering', 'place', 'much', 'closer', '.'], ['In', 'fact', ',', 'downdraft', 'appears', 'constant', '10:13-10:16', 'p.m.', 'intermittent', 'several', 'choppers', 'passed', 'overhead', '.'], ['According', 'Carlson', ',', 'owner', 'tape', 'maintains', 'law', 'enforcement', 'investigators', 'never', 'asked', 'see', 'footage', '.'], ['A', 'preliminary', 'report', 'shooting', 'released', 'LVMPD', 'Friday', 'lists', 'seven', 'victims', '“', 'placed', '”', 'outside', 'venue', ',', 'two', 'half', 'mile', 'away', '.'], ['However', ',', 'official', 'report', 'failed', 'catalogue', 'dead', 'woman', 'shot', 'parking', 'lot', 'Haven', 'Street', 'business', '.'], ['The', 'following', 'image', 'taken', 'page', '34', 'LVMPD', 'preliminary', 'report', 'shows', 'seven', 'victims', 'locations', 'death', 'numbered', 'yellow', '.'], ['The', 'next', 'photo', 'shows', 'unnamed', 'victim', 'located', '.'], ['The', 'victim', 'seen', 'dragged', 'following', 'video', '.'], ['The', 'following', 'day', ',', 'several', 'men', ',', 'one', 'presumably', 'Fox', 'News', 'anchor', 'Sean', 'Hannity', '(', 'heavily', 'guarded', 'five-man', 'security', 'team', ')', ',', 'received', 'mobile', 'haircuts', 'parking', 'lot', ',', 'nearly', 'spot', 'victim', '’', 'body', 'dragged', '.'], ['Who', 'victim', '?'], ['Will', 'F.B.I', '.'], ['LVMPD', 'please', 'explain', 'Hell', 'going', '?'], ['How', 'victim', 'overlooked', 'investigators', 'known', 'Intellihub', '?'], ['Who', 'victim', '?'], ['Why', 'people', 'getting', 'haircuts', 'crime', 'scene', '?'], ['How', 'many', 'victims', 'went', 'ignored', 'investigators', '?'], ['NASA', 'releases', 'images', 'captured', 'record-breaking', '3.79', 'billion', 'miles', 'Earth'], ['NASA', 'whole', 'lot', 'fancy', 'image-gathering', 'hardware', 'Earth', 'space', ',', '’', 'seen', 'countless', 'stunning', 'snapshots', 'taken', 'Earth', 'well', 'nearby', 'planets', 'like', 'Mars', ',', 'Jupiter', 'Saturn', '.'], ['The', 'pictures', 'often', 'gorgeously', 'detailed', 'eye', 'candy', ',', 'latest', 'batch', 'images', 'space', 'agency', 'remarkable', 'entirely', 'different', 'reason', '.'], ['Captured', 'NASA', '’', 'New', 'Horizons', 'spacecraft', ',', 'images', 'gathered', 'greatest', 'distance', 'Earth', 'history', 'mankind', '.'], ['So', ',', 'far', '“', 'farthest', 'ever', '”', '?'], ['Right', 'around', '3.79', 'billion', 'miles', '.'], ['Yeah', ',', '’', 'kind', 'crazy', '.'], ['There', 'three', 'images', 'total', ',', 'focusing', 'different', 'distant', 'object', '.'], ['The', 'subjects', 'include', '‘', 'Wishing', 'Well', '’', 'star', 'cluster', 'well', 'two', 'large', 'objects', 'Kuiper', 'Belt', 'never', 'observed', 'distance', '.'], ['“', 'New', 'Horizons', 'long', 'mission', 'firsts', '—', 'first', 'explore', 'Pluto', ',', 'first', 'explore', 'Kuiper', 'Belt', ',', 'fastest', 'spacecraft', 'ever', 'launched', ',', '”', 'New', 'Horizons', 'Principal', 'Investigator', 'Alan', 'Stern', ',', 'Southwest', 'Research', 'Institute', 'Boulder', ',', 'Colorado', ',', 'notes', 'statement', '.'], ['“', 'And', ',', '’', 'able', 'make', 'images', 'farther', 'Earth', 'spacecraft', 'history', '.', '”'], ['The', 'images', ',', 'seen', '(', 'Kuiper', 'Belt', 'objects', ')', '(', 'Wishing', 'Well', 'cluster', ')', ',', 'somewhat', 'grainy', 'detailed', '’', 'seen', 'NASA', ',', '’', 'make', 'feat', 'less', 'remarkable', '.'], ['New', 'Horizons', 'originally', 'launched', 'way', 'back', 'early', '2006', ',', 'spacecraft', 'made', 'close', 'passes', 'number', 'planets', 'decade', 'cruising', 'Solar', 'System', '.'], ['Its', 'primary', 'mission', 'set', 'last', 'roughly', '10', 'years', ',', 'extended', 'became', 'clear', 'spacecraft', 'healthy', 'enough', 'continue', 'sending', 'back', 'observations', 'longer', '.'], ['Its', 'new', 'extended', 'mission', 'wrap', 'early', '2021', 'performs', 'number', 'flybys', 'large', 'objects', 'Kuiper', 'Belt', 'scientists', 'want', 'learn', '.'], ['However', ',', 'might', 'last', 'hear', 'New', 'Horizons', ',', 'power', 'source', 'could', 'continue', 'provide', 'life', '2026', 'beyond', '.'], ['If', 'makes', 'long', ',', 'NASA', 'plans', 'use', 'spacecraft', 'study', 'outer', 'heliosphere', '.'], ['Jewish', 'Pro-Israel', 'Students', 'Kicked', 'Off', 'University', 'Board', 'Opposing', 'BDS'], ['First', 'came', 'Jews', '.'], ['And', 'came', 'everyone', 'else', '.'], ['Jewish', 'students', 'already', 'faced', 'plenty', 'harassment', 'hate', 'McGill', '.'], ['The', 'latest', 'incident', 'Canadian', 'university', 'comes', 'rather', 'blatant', 'agenda', '.'], ['A', 'Jewish', 'student', 'McGill', 'University', 'kicked', 'student', 'government', 'board', '“', 'conflicts', 'interest', '”', 'due', 'pro-Israel', 'activism', '.'], ['Third-year', 'student', 'Noah', 'Lew', 'one', '12', 'board', 'members', 'general', 'assembly', 'ratification', 'Monday', 'evening', 'following', 'victory', 'vice-president', 'finance', 'Arts', 'Undergraduate', 'Society', '.'], ['The', 'ratification', 'vote', 'typically', 'mere', 'formality', ',', 'Monday', '’', 'different', 'due', 'Democratize', 'Student', 'Society', 'McGill', 'University', '(', 'SSMU', ')', ',', 'organization', 'established', 'resist', 'university', '’', 'ban', 'Boycott', ',', 'Divestment', 'Sanctions', '(', 'BDS', ')', 'movement', 'campus', '.'], ['Democratize', 'SSMU', 'able', 'pass', 'motion', 'required', 'board', 'member', 'voted', 'upon', 'separately', 'grounds', '’', 'fan', 'names', '.'], ['When', 'Lew', '’', 'turn', ',', 'voted', ',', '105', '73', '12', 'abstaining', ',', 'applause', 'following', 'vote', '.'], ['Two', 'students', 'criticized', 'BDS', ',', 'Alexander', 'Scheffel', 'Josephine', 'Wright', 'O', '’', 'Manique', ',', 'also', 'voted', '.'], ['Democratize', 'SSMU', 'targeted', 'Lew', 'two', 'students', 'board', 'connections', 'Canadian', 'Jewish', 'Political', 'Affairs', 'Committee', '(', 'CJPAC', ')', 'involved', 'getting', 'BDS', 'ban', 'passed', ',', 'Democratize', 'SSMU', 'claimed', '“', 'conflicts', 'interests', '.', '”'], ['Somehow', 'I', \"n't\", 'think', 'member', 'Muslim', 'student', 'group', 'supporting', 'BDS', 'would', 'considered', 'conflict', 'interest', '.'], ['But', 'campus', 'anti-Israel', 'crowd', 'working', 'rather', 'hard', 'intimidate', 'penalize', 'anyone', 'involved', 'pro-Israel', 'organizations', '.'], ['And', 'keep', 'racist', 'boycott', 'movement', 'going', 'maintaining', 'control', 'student', 'governments', '.'], ['Lew', 'shared', 'experience', 'Facebook', '.'], ['“', 'I', 'doubt', 'information', 'circulated', 'campaign', 'run', 'prior', 'vote', 'Jewish', 'identity', ',', 'nothing', ',', '”', 'wrote', 'Lew', '.'], ['“', 'I', 'blocked', 'able', 'participate', 'student', 'government', 'I', 'Jewish', ',', 'I', 'affiliated', 'Jewish', 'organizations', ',', 'I', 'believe', 'right', 'Jewish', 'self-determination.', '”', 'Lew', 'added', 'experience', 'shows', 'inherent', 'anti-Semitism', 'BDS', 'movement', '.'], ['“', 'If', 'BDS', 'anti-Semitic', ',', 'BDS-led', 'campaign', 'name', 'shame', 'affiliation', 'Jewish', 'organization', ',', 'call', 'students', 'remove', 'student', 'government', 'reason', '?', '”', 'wrote', 'Lew', '.'], ['“', 'If', 'BDS', 'anti-Semitic', ',', 'I', 'barred', 'participating', 'student', 'government', 'Jewish', 'identity', '?', '”'], ['There', 'details', 'petition', '.'], ['On', 'Monday', 'night', ',', 'three', 'students', 'removed', 'Board', 'Directors', 'Students', '’', 'Society', 'McGill', 'University', '(', 'SSMU', ')', ',', 'McGill', '’', 'main', 'student', 'government', '.'], ['All', 'three', 'targeted', 'removal', 'either', 'Jewish', 'vocally', 'opposed', 'anti-Jewish', 'discrimination', 'campus', '.'], ['This', 'episode', 'utterly', 'unacceptable', ',', 'merely', 'latest', 'long', 'string', 'antisemitic', 'incidents', 'university', '.'], ['Indeed', ',', 'according', 'eyewitnesses', ',', 'one', 'members', 'mob', 'removed', 'three', 'directors', 'Igor', 'Sadikov', '.'], ['You', 'remember', 'Sadikov', 'student', 'politician', 'February', 'told', 'followers', '“', 'punch', 'Zionist', 'today.', '”', 'It', 'unclear', 'whether', 'Sadikov', 'faced', 'disciplinary', 'action', 'incitement', 'violence', 'administration', '.'], ['Antisemitism', 'McGill', 'emerge', 'vacuum', '.'], ['Rather', ',', 'nurtured', 'part', 'toxic', 'campus', 'press', ',', 'especially', 'McGill', 'Daily', ',', 'publication', 'openly', 'refuses', 'publish', '“', 'Zionist', '”', 'content', '.'], ['In', 'practice', ',', 'prevents', 'McGill', '’', 'Jewish', 'community', 'defending', 'absurd', 'attacks', 'subjected', '.'], ['If', 'Daily', 'committed', 'systematically', 'excluding', 'voices', 'ethno-religious', 'community', 'campus', ',', 'continue', 'receive', 'automatic', 'student', 'funding', ',', '.'], ['The', 'double', 'standard', 'pretty', 'clear', '.'], ['And', 'know', 'exactly', 'reaction', 'would', 'student', 'paper', 'refused', 'publish', 'pro-Islamist', 'content', '.'], ['DRC', ':', 'Fresh', 'Ebola', 'outbreak', 'kills', 'two', 'Equateur', 'Province'], ['The', 'World', 'Health', 'Organization', '(', 'WHO', ')', 'said', 'Tuesday', 'taking', 'steps', 'help', 'deal', 'new', 'outbreak', 'Ebola', 'Democratic', 'Republic', 'Congo', \"'s\", 'rural', 'northwest', ',', 'two', 'cases', 'deadly', 'virus', 'confirmed', 'market', 'town', 'Bikoro', '.'], ['Congo', \"'s\", 'Health', 'Ministry', 'said', 'two', 'five', 'samples', 'sent', 'National', 'Institute', 'Biological', 'Research', 'Kinshasa', ',', 'came', 'back', 'positive', 'disease', '.'], ['The', 'samples', 'gathered', 'health', 'officials', 'Equateur', 'Province', 'notified', 'Kinshasa', 'May', '3', '21', 'cases', 'hemorrhagic', 'fever', 'Ikoko', 'Impenge', 'area', ',', 'including', '17', 'deaths', ',', 'according', 'WHO', 'Congo', \"'s\", 'government', '.'], ['What', 'Ebola', '?'], ['Rare', 'deadly', ',', 'viral', 'disease', 'commonly', 'affecting', 'primates', 'humans', '.'], ['Initial', 'symptoms', 'include', 'fever', ',', 'headache', ',', 'joint', 'muscle', 'aches', ',', 'weakness', ',', 'diarrhoea', ',', 'vomiting', ',', 'stomach', 'pain', 'lack', 'appetite', 'cases', 'internal', 'external', 'bleeding', ',', 'according', 'WHO', '.'], ['Where', 'originate', '?'], ['Ebola', 'virus', 'disease', '(', 'EVD', ')', 'first', 'discovered', '1976', 'two', 'simultaneous', 'outbreaks', '.'], ['One', 'Nzara', 'South', 'Sudan', '.'], ['The', 'outbreak', 'Yambuku', 'Zaire', 'DR', 'Congo', '.'], ['The', 'latter', 'occurred', 'village', 'near', 'Ebola', 'River', ',', 'disease', 'takes', 'name', '.'], ['Why', 'dangerous', '?'], ['The', 'average', 'Ebola', 'fatality', 'rate', '50', 'percent', '.'], ['But', 'rates', 'varied', '25', 'percent', '90', 'percent', 'recent', 'outbreaks', '.'], ['There', 'yet', 'proven', 'cure', 'available', 'Ebola', ',', 'though', 'vaccines', 'tested', '.'], ['Some', 'people', 'recovered', 'Ebola', 'developed', 'long-term', 'complications', ',', 'joint', 'vision', 'problems', '.'], ['It', 'known', 'people', 'recover', 'Ebola', 'succumb', 'disease', '.'], ['Why', 'keep', 'coming', 'back', '?'], ['The', 'disease', 'infects', 'humans', 'close', 'contact', 'infected', 'animals', ',', 'including', 'chimpanzees', ',', 'fruit', 'bats', 'forest', 'antelope', '.'], ['In', 'Africa', 'outbreaks', 'happen', ',', 'particular', 'species', 'fruit', 'bats', 'considered', 'natural', 'hosts', 'Ebola', 'virus', '.'], ['Infected', 'bats', 'believed', 'transmit', 'disease', 'humans', ',', 'indirectly', 'animals', 'hunted', 'meat', '.'], ['The', 'family', 'first', 'victim', '2014', 'outbreak', ',', 'two-year-old', 'child', ',', 'hunted', 'bats', 'believed', 'bushmeat', 'origin', 'outbreak', '.'], ['An', 'estimated', 'five', 'million', 'tonnes', 'bushmeat', 'consumed', 'continent', 'every', 'year', ',', 'according', 'Centre', 'International', 'Forestry', 'Research', '.'], ['The', 'virus', 'spreads', 'humans', 'direct', 'contact', 'infected', 'blood', ',', 'bodily', 'fluids', 'organs', ',', 'indirectly', 'contact', 'contaminated', 'environments', '.'], ['Even', 'funerals', 'Ebola', 'victims', 'risk', ',', 'mourners', 'direct', 'contact', 'body', 'deceased', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Cleaning text of stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenized_docs_no_stopwords = []\n",
    "\n",
    "for doc in tokenized_docs:\n",
    "    new_term_vector = []\n",
    "    for word in doc:\n",
    "        if not word in stopwords.words('english'):\n",
    "            new_term_vector.append(word)\n",
    "    tokenized_docs_no_stopwords.append(new_term_vector)\n",
    "\n",
    "print(tokenized_docs_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 'poll', 'grant', 'access', 'Freedom', 'Outpost', 'update', 'free', 'charge', '.'], ['You', 'may', 'opt', 'anytime', '.'], ['You', 'also', 'agree', 'site', \"'s\", 'Privacy', 'Policy', 'Terms', 'Use', '.'], ['The', 'aide', 'named', 'Imran', 'Awan', ',', 'wife', 'Hina', 'Alvi', ',', 'brother', 'Abid', 'Jamal', ',', 'friend', 'Rao', 'Abbas', ',', 'Pakistani-born', 'aide', '.'], ['And', 'father', 'Muslim', 'spy', 'ring', 'Imran', 'Awan', 'transferred', 'USB', 'drive', 'Pakistani', 'senator', 'former', 'head', 'Pakistani', 'intelligence', 'agency', '.'], ['Capitol', 'Police', 'looking', 'massive', 'amount', 'data', 'Awans', 'reportedly', 'downloaded', 'congressional', 'system', ',', 'thousand', 'illegal', 'logins', 'made', 'official', 'system', ',', 'possible', 'theft', 'ten', 'thousand', 'dollar', 'congressional', 'equipment', 'fraud', 'sent', 'foreign', 'government', 'group', '.'], ['No', 'wonder', 'Democrats', 'tried', 'squirrel', 'jihad', 'spy', 'country', '.'], ['Congress', 'must', 'investigate', 'act', '.'], ['“', 'Witness', 'Said', 'Awan', 'Wiretapped', 'Her', ',', 'Then', 'Bank', 'Account', 'She', 'Controlled', 'Was', 'Drained', ',', '”', 'Luke', 'Rosiak', ',', 'Daily', 'Caller', 'News', 'Foundation', ',', 'May', '21', ',', '2018', '(', 'thanks', 'Todd', ')', ':'], ['After', 'former', 'Democratic', 'IT', 'aide', 'Imran', 'Awan', 'allegedly', 'threatened', 'stepmother', 'talk', 'police', ',', 'email', 'account', 'accessed', 'suspicious', 'way', 'lawyer', 'one', 'Awan', '’', 'brother', 'found', 'emailed', 'FBI', 'specific', 'date', 'lashed', ':', '“', 'You', '’', 'liar', ',', '’', '?', '”', 'Days', ',', 'bank', 'account', 'stepmother', 'controlled', 'almost', 'completely', 'drained', 'payment', 'Imran', '’', 'brother', ',', 'Abid', 'Awan', ',', 'bank', 'record', 'show', '—', 'said', 'afraid', 'press', 'criminal', 'charge', 'claim', 'threatened', '.'], ['The', 'stepmother', ',', 'Samina', 'Gilani', ',', 'also', 'previously', 'said', 'Imran', 'stole', 'two', 'laptop', '.'], ['Imran', ',', 'Abid', 'Jamal', 'Awan', '—', 'along', 'Imran', '’', 'wife', ',', 'Hina', 'Alvi', ',', 'friend', '—', 'worked', 'IT', 'administrator', '1', 'every', '5', 'House', 'Democrats', 'could', 'read', 'email', 'file', 'police', 'banned', 'network', 'February', '2017for', '“', 'numerous', 'violation', 'House', 'security', 'policies.', '”', 'Months', 'later', ',', 'none', 'family', 'jail', ',', 'stepmother', 'witness', 'said', 'Imran', 'Abid', 'used', 'freedom', 'try', 'steer', 'outcome', 'case', 'since', ',', 'including', 'threatening', 'cooperate', 'authority', ',', 'TheDCNF', 'previously', 'reported', '.'], ['In', 'April', '2016', ',', 'House', '’', 'Chief', 'Administrative', 'Officer', '(', 'CAO', ')', 'detected', 'allegedly', 'falsified', 'purchase', 'order', ',', 'Inspector', 'General', 'quickly', 'expanded', 'scope', 'investigate', 'cyber', 'violation', ',', 'finding', 'member', 'Awan', 'family', 'improperly', 'accessed', 'congressman', '’', 'server', 'House', 'Democratic', 'Caucus', 'server', 'thousand', 'time', '.'], ['Though', 'House', 'official', 'suspected', 'equipment', 'stolen', ',', 'Capitol', 'Police', 'search', 'home', ',', 'The', 'Daily', 'Caller', 'News', 'Foundation', 'learned', ',', 'ban', 'network', 'nearly', 'year', 'later', '.'], ['In', 'meantime', ',', 'evidence', 'appears', 'compromised', ':', 'In', 'December', '2016', ',', 'CAO', 'notified', 'congressman', 'caucus', 'server', 'physically', 'disappeared', '.'], ['Though', 'Abid', 'played', 'prominent', 'role', 'late-2016', 'IG', 'report', ',', 'arrested', ',', 'congressman', 'saying', 'criminal', 'investigation', 'ongoing', '.'], ['In', 'January', '2017', ',', 'day', 'around', 'father', '’', 'death', ',', 'Abid', 'removed', 'Gilani', 'beneficiary', 'father', '’', 'life', 'insurance', 'replaced', ',', 'led', 'lawsuit', ',', 'TheDCNF', 'previously', 'reported', '.'], ['Abid', '’', 'attorney', ',', 'Jim', 'Bacon', ',', 'used', 'life', 'insurance', 'lawsuit', 'force', 'Gilani', 'sit', 'sworn', 'deposition', 'Oct.', '4', ',', '2017', 'told', 'reveal', 'told', 'FBI', 'congressional', 'criminal', 'probe', 'tried', 'get', 'find', 'detail', 'investigator', '.'], ['In', 'one', 'exchange', ',', 'Bacon', 'knew', 'emailed', 'FBI', '.'], ['BACON', 'Q', ':', '[', 'redacted', ']', 'email', 'address', ',', '’', '?'], ['And', 'send', 'email', 'address', 'including', 'two', 'email', 'FBI', ',', '’', '?'], ['GILANI', 'A', ':', 'Yes', ',', 'long', 'time', 'ago', '.'], ['Q', ':', 'No', ',', 'long', 'time', 'ago', '.'], ['March', '5th', ',', '2017', '.'], ['March', '6th', ',', '2017', '.'], ['Ma', '’', ',', 'lied', ',', '’', '?'], ['You', 'lied', ',', '’', '?'], ['You', '’', 'liar', ',', '’', '?'], ['A', ':', 'I', 'forgot', '.'], ['It', 'mind', '.'], ['BACON', ':', 'Ah', '.'], ['I', 'think', 'need', 'take', 'break', 'I', 'explode', '.'], ['Bacon', 'respond', 'question', 'TheDCNF', 'knew', 'Gilani', 'emailed', 'FBI', 'dates…', '.'], ['Article', 'posted', 'permission', 'Pamela', 'Geller'], ['Pamela', 'Geller', \"'s\", 'commitment', 'freedom', 'jihad', 'Shariah', 'shine', 'forth', 'book'], ['PROOF', ':', 'The', 'LVMPD', 'And', 'FBI', 'Failed', 'To', 'Catalog', 'At', 'Least', 'One', 'Deceased', 'Las', 'Vegas', 'Massacre', 'Victim', 'As', 'Death', 'Toll', 'Rises'], ['In', 'described', 'gross', 'negligence', 'massive', 'cover-up', 'truth', ',', 'F.B.I', '.'], ['LVMPD', 'failed', 'record', 'death', 'least', 'one', 'shooting', 'victim', 'killed', 'massacre'], ['LAS', 'VEGAS', '(', 'INTELLIHUB', ')', '—', 'The', 'Las', 'Vegas', 'Metropolitan', 'Police', 'Department', 'Federal', 'Bureau', 'Investigation', 'failed', 'catalogue', 'least', 'one', 'deceased', 'victim', '1', 'October', 'massacre', 'reportedly', 'left', '58', 'people', 'dead', '.'], ['The', '59th', 'victim', ',', 'currently', 'unnamed', 'completely', 'botched', 'investigation', 'cover-up', ',', 'shot', 'killed', 'parking', 'lot', 'nearby', 'business', 'attack', '.'], ['The', 'woman', '’', 'lifeless', 'body', 'seen', 'drug', 'across', 'parking', 'lot', 'several', 'men', 'placed', 'body', 'behind', 'pick-up', 'truck', 'gunfire', 'continued', '.'], ['The', 'event', 'reported', 'Intellihub', '’', 'Shepard', 'Ambellas', 'Nov.', '11', ',', '2017', ',', 'article', 'titled', 'Private', 'surveillance', 'footage', 'reveals', '“', 'helicopter', 'hovering', 'overhead', '”', 'time', 'Las', 'Vegas', 'Massacre', ',', 'FBI', 'never', 'asked', 'tape', ',', 'excerpt', 'footage', 'aired', 'Tucker', 'Carlson', 'Tonight', '.'], ['At', '10:16', 'p.m.', ',', 'two', 'men', 'drag', '“', 'fallen', 'victim', '”', 'across', 'parking', 'lot', '.'], ['The', 'men', 'position', 'victim', 'behind', 'Ford', 'pickup', 'truck', ',', 'presumably', 'shield', 'victim', 'taking', 'incoming', 'round', 'attempted', 'give', 'victim', 'medical', 'assistance', '.'], ['“', 'Later', 'ten-twenty-four', 'p.m.', ',', 'one', 'men', 'place', 'shirt', 'across', 'victim', '’', 'face', 'ten-thirty-two', 'man', 'place', 'appears', 'blanket', 'towel', 'body', 'given', 'hope', ',', '”', 'Tucker', 'Carlson', 'said', '.'], ['“', 'Police', 'arrive', 'area', 'first', 'time', 'around', 'ten-forty-five', 'p.m.', 'body', 'still', 'there.', '”', 'The', 'victim', '’', 'body', 'eventually', 'loaded', 'back', 'Ford', 'Raptor', 'pickup', 'truck', '11:50', 'p.m.', 'taken', 'away', '.'], ['Astonishingly', ',', 'time', '10:13', 'p.m.', '10:16', 'p.m.', 'good', 'amount', 'debris', 'seen', 'pushed', 'downward', 'sideways', 'front', 'camera', 'Carlson', 'claim', '“', 'helicopter', 'hovering', 'overhead.', '”', 'A', 'quick', 'review', 'flight', 'record', 'time', 'reveals', 'squadron', 'EC-130', 'Eurocopters', 'departed', 'Maverick', 'Leasing', 'LLC', '10:12', 'p.m.', ',', 'several', 'appear', 'overflown', 'parking', 'lot', 'victim', 'debris', 'seen', '.'], ['However', ',', 'departure', 'chopper', 'fact', 'several', 'overflew', 'parking', 'lot', 'explain', 'debris', 'kicked', 'heavy', 'downdraft', ',', 'prop', 'wash', ',', 'possibly', 'helicopter', 'hovering', 'place', 'much', 'closer', '.'], ['In', 'fact', ',', 'downdraft', 'appears', 'constant', '10:13-10:16', 'p.m.', 'intermittent', 'several', 'chopper', 'passed', 'overhead', '.'], ['According', 'Carlson', ',', 'owner', 'tape', 'maintains', 'law', 'enforcement', 'investigator', 'never', 'asked', 'see', 'footage', '.'], ['A', 'preliminary', 'report', 'shooting', 'released', 'LVMPD', 'Friday', 'list', 'seven', 'victim', '“', 'placed', '”', 'outside', 'venue', ',', 'two', 'half', 'mile', 'away', '.'], ['However', ',', 'official', 'report', 'failed', 'catalogue', 'dead', 'woman', 'shot', 'parking', 'lot', 'Haven', 'Street', 'business', '.'], ['The', 'following', 'image', 'taken', 'page', '34', 'LVMPD', 'preliminary', 'report', 'show', 'seven', 'victim', 'location', 'death', 'numbered', 'yellow', '.'], ['The', 'next', 'photo', 'show', 'unnamed', 'victim', 'located', '.'], ['The', 'victim', 'seen', 'dragged', 'following', 'video', '.'], ['The', 'following', 'day', ',', 'several', 'men', ',', 'one', 'presumably', 'Fox', 'News', 'anchor', 'Sean', 'Hannity', '(', 'heavily', 'guarded', 'five-man', 'security', 'team', ')', ',', 'received', 'mobile', 'haircut', 'parking', 'lot', ',', 'nearly', 'spot', 'victim', '’', 'body', 'dragged', '.'], ['Who', 'victim', '?'], ['Will', 'F.B.I', '.'], ['LVMPD', 'please', 'explain', 'Hell', 'going', '?'], ['How', 'victim', 'overlooked', 'investigator', 'known', 'Intellihub', '?'], ['Who', 'victim', '?'], ['Why', 'people', 'getting', 'haircut', 'crime', 'scene', '?'], ['How', 'many', 'victim', 'went', 'ignored', 'investigator', '?'], ['NASA', 'release', 'image', 'captured', 'record-breaking', '3.79', 'billion', 'mile', 'Earth'], ['NASA', 'whole', 'lot', 'fancy', 'image-gathering', 'hardware', 'Earth', 'space', ',', '’', 'seen', 'countless', 'stunning', 'snapshot', 'taken', 'Earth', 'well', 'nearby', 'planet', 'like', 'Mars', ',', 'Jupiter', 'Saturn', '.'], ['The', 'picture', 'often', 'gorgeously', 'detailed', 'eye', 'candy', ',', 'latest', 'batch', 'image', 'space', 'agency', 'remarkable', 'entirely', 'different', 'reason', '.'], ['Captured', 'NASA', '’', 'New', 'Horizons', 'spacecraft', ',', 'image', 'gathered', 'greatest', 'distance', 'Earth', 'history', 'mankind', '.'], ['So', ',', 'far', '“', 'farthest', 'ever', '”', '?'], ['Right', 'around', '3.79', 'billion', 'mile', '.'], ['Yeah', ',', '’', 'kind', 'crazy', '.'], ['There', 'three', 'image', 'total', ',', 'focusing', 'different', 'distant', 'object', '.'], ['The', 'subject', 'include', '‘', 'Wishing', 'Well', '’', 'star', 'cluster', 'well', 'two', 'large', 'object', 'Kuiper', 'Belt', 'never', 'observed', 'distance', '.'], ['“', 'New', 'Horizons', 'long', 'mission', 'first', '—', 'first', 'explore', 'Pluto', ',', 'first', 'explore', 'Kuiper', 'Belt', ',', 'fastest', 'spacecraft', 'ever', 'launched', ',', '”', 'New', 'Horizons', 'Principal', 'Investigator', 'Alan', 'Stern', ',', 'Southwest', 'Research', 'Institute', 'Boulder', ',', 'Colorado', ',', 'note', 'statement', '.'], ['“', 'And', ',', '’', 'able', 'make', 'image', 'farther', 'Earth', 'spacecraft', 'history', '.', '”'], ['The', 'image', ',', 'seen', '(', 'Kuiper', 'Belt', 'object', ')', '(', 'Wishing', 'Well', 'cluster', ')', ',', 'somewhat', 'grainy', 'detailed', '’', 'seen', 'NASA', ',', '’', 'make', 'feat', 'le', 'remarkable', '.'], ['New', 'Horizons', 'originally', 'launched', 'way', 'back', 'early', '2006', ',', 'spacecraft', 'made', 'close', 'pass', 'number', 'planet', 'decade', 'cruising', 'Solar', 'System', '.'], ['Its', 'primary', 'mission', 'set', 'last', 'roughly', '10', 'year', ',', 'extended', 'became', 'clear', 'spacecraft', 'healthy', 'enough', 'continue', 'sending', 'back', 'observation', 'longer', '.'], ['Its', 'new', 'extended', 'mission', 'wrap', 'early', '2021', 'performs', 'number', 'flybys', 'large', 'object', 'Kuiper', 'Belt', 'scientist', 'want', 'learn', '.'], ['However', ',', 'might', 'last', 'hear', 'New', 'Horizons', ',', 'power', 'source', 'could', 'continue', 'provide', 'life', '2026', 'beyond', '.'], ['If', 'make', 'long', ',', 'NASA', 'plan', 'use', 'spacecraft', 'study', 'outer', 'heliosphere', '.'], ['Jewish', 'Pro-Israel', 'Students', 'Kicked', 'Off', 'University', 'Board', 'Opposing', 'BDS'], ['First', 'came', 'Jews', '.'], ['And', 'came', 'everyone', 'else', '.'], ['Jewish', 'student', 'already', 'faced', 'plenty', 'harassment', 'hate', 'McGill', '.'], ['The', 'latest', 'incident', 'Canadian', 'university', 'come', 'rather', 'blatant', 'agenda', '.'], ['A', 'Jewish', 'student', 'McGill', 'University', 'kicked', 'student', 'government', 'board', '“', 'conflict', 'interest', '”', 'due', 'pro-Israel', 'activism', '.'], ['Third-year', 'student', 'Noah', 'Lew', 'one', '12', 'board', 'member', 'general', 'assembly', 'ratification', 'Monday', 'evening', 'following', 'victory', 'vice-president', 'finance', 'Arts', 'Undergraduate', 'Society', '.'], ['The', 'ratification', 'vote', 'typically', 'mere', 'formality', ',', 'Monday', '’', 'different', 'due', 'Democratize', 'Student', 'Society', 'McGill', 'University', '(', 'SSMU', ')', ',', 'organization', 'established', 'resist', 'university', '’', 'ban', 'Boycott', ',', 'Divestment', 'Sanctions', '(', 'BDS', ')', 'movement', 'campus', '.'], ['Democratize', 'SSMU', 'able', 'pas', 'motion', 'required', 'board', 'member', 'voted', 'upon', 'separately', 'ground', '’', 'fan', 'name', '.'], ['When', 'Lew', '’', 'turn', ',', 'voted', ',', '105', '73', '12', 'abstaining', ',', 'applause', 'following', 'vote', '.'], ['Two', 'student', 'criticized', 'BDS', ',', 'Alexander', 'Scheffel', 'Josephine', 'Wright', 'O', '’', 'Manique', ',', 'also', 'voted', '.'], ['Democratize', 'SSMU', 'targeted', 'Lew', 'two', 'student', 'board', 'connection', 'Canadian', 'Jewish', 'Political', 'Affairs', 'Committee', '(', 'CJPAC', ')', 'involved', 'getting', 'BDS', 'ban', 'passed', ',', 'Democratize', 'SSMU', 'claimed', '“', 'conflict', 'interest', '.', '”'], ['Somehow', 'I', \"n't\", 'think', 'member', 'Muslim', 'student', 'group', 'supporting', 'BDS', 'would', 'considered', 'conflict', 'interest', '.'], ['But', 'campus', 'anti-Israel', 'crowd', 'working', 'rather', 'hard', 'intimidate', 'penalize', 'anyone', 'involved', 'pro-Israel', 'organization', '.'], ['And', 'keep', 'racist', 'boycott', 'movement', 'going', 'maintaining', 'control', 'student', 'government', '.'], ['Lew', 'shared', 'experience', 'Facebook', '.'], ['“', 'I', 'doubt', 'information', 'circulated', 'campaign', 'run', 'prior', 'vote', 'Jewish', 'identity', ',', 'nothing', ',', '”', 'wrote', 'Lew', '.'], ['“', 'I', 'blocked', 'able', 'participate', 'student', 'government', 'I', 'Jewish', ',', 'I', 'affiliated', 'Jewish', 'organization', ',', 'I', 'believe', 'right', 'Jewish', 'self-determination.', '”', 'Lew', 'added', 'experience', 'show', 'inherent', 'anti-Semitism', 'BDS', 'movement', '.'], ['“', 'If', 'BDS', 'anti-Semitic', ',', 'BDS-led', 'campaign', 'name', 'shame', 'affiliation', 'Jewish', 'organization', ',', 'call', 'student', 'remove', 'student', 'government', 'reason', '?', '”', 'wrote', 'Lew', '.'], ['“', 'If', 'BDS', 'anti-Semitic', ',', 'I', 'barred', 'participating', 'student', 'government', 'Jewish', 'identity', '?', '”'], ['There', 'detail', 'petition', '.'], ['On', 'Monday', 'night', ',', 'three', 'student', 'removed', 'Board', 'Directors', 'Students', '’', 'Society', 'McGill', 'University', '(', 'SSMU', ')', ',', 'McGill', '’', 'main', 'student', 'government', '.'], ['All', 'three', 'targeted', 'removal', 'either', 'Jewish', 'vocally', 'opposed', 'anti-Jewish', 'discrimination', 'campus', '.'], ['This', 'episode', 'utterly', 'unacceptable', ',', 'merely', 'latest', 'long', 'string', 'antisemitic', 'incident', 'university', '.'], ['Indeed', ',', 'according', 'eyewitness', ',', 'one', 'member', 'mob', 'removed', 'three', 'director', 'Igor', 'Sadikov', '.'], ['You', 'remember', 'Sadikov', 'student', 'politician', 'February', 'told', 'follower', '“', 'punch', 'Zionist', 'today.', '”', 'It', 'unclear', 'whether', 'Sadikov', 'faced', 'disciplinary', 'action', 'incitement', 'violence', 'administration', '.'], ['Antisemitism', 'McGill', 'emerge', 'vacuum', '.'], ['Rather', ',', 'nurtured', 'part', 'toxic', 'campus', 'press', ',', 'especially', 'McGill', 'Daily', ',', 'publication', 'openly', 'refuse', 'publish', '“', 'Zionist', '”', 'content', '.'], ['In', 'practice', ',', 'prevents', 'McGill', '’', 'Jewish', 'community', 'defending', 'absurd', 'attack', 'subjected', '.'], ['If', 'Daily', 'committed', 'systematically', 'excluding', 'voice', 'ethno-religious', 'community', 'campus', ',', 'continue', 'receive', 'automatic', 'student', 'funding', ',', '.'], ['The', 'double', 'standard', 'pretty', 'clear', '.'], ['And', 'know', 'exactly', 'reaction', 'would', 'student', 'paper', 'refused', 'publish', 'pro-Islamist', 'content', '.'], ['DRC', ':', 'Fresh', 'Ebola', 'outbreak', 'kill', 'two', 'Equateur', 'Province'], ['The', 'World', 'Health', 'Organization', '(', 'WHO', ')', 'said', 'Tuesday', 'taking', 'step', 'help', 'deal', 'new', 'outbreak', 'Ebola', 'Democratic', 'Republic', 'Congo', \"'s\", 'rural', 'northwest', ',', 'two', 'case', 'deadly', 'virus', 'confirmed', 'market', 'town', 'Bikoro', '.'], ['Congo', \"'s\", 'Health', 'Ministry', 'said', 'two', 'five', 'sample', 'sent', 'National', 'Institute', 'Biological', 'Research', 'Kinshasa', ',', 'came', 'back', 'positive', 'disease', '.'], ['The', 'sample', 'gathered', 'health', 'official', 'Equateur', 'Province', 'notified', 'Kinshasa', 'May', '3', '21', 'case', 'hemorrhagic', 'fever', 'Ikoko', 'Impenge', 'area', ',', 'including', '17', 'death', ',', 'according', 'WHO', 'Congo', \"'s\", 'government', '.'], ['What', 'Ebola', '?'], ['Rare', 'deadly', ',', 'viral', 'disease', 'commonly', 'affecting', 'primate', 'human', '.'], ['Initial', 'symptom', 'include', 'fever', ',', 'headache', ',', 'joint', 'muscle', 'ache', ',', 'weakness', ',', 'diarrhoea', ',', 'vomiting', ',', 'stomach', 'pain', 'lack', 'appetite', 'case', 'internal', 'external', 'bleeding', ',', 'according', 'WHO', '.'], ['Where', 'originate', '?'], ['Ebola', 'virus', 'disease', '(', 'EVD', ')', 'first', 'discovered', '1976', 'two', 'simultaneous', 'outbreak', '.'], ['One', 'Nzara', 'South', 'Sudan', '.'], ['The', 'outbreak', 'Yambuku', 'Zaire', 'DR', 'Congo', '.'], ['The', 'latter', 'occurred', 'village', 'near', 'Ebola', 'River', ',', 'disease', 'take', 'name', '.'], ['Why', 'dangerous', '?'], ['The', 'average', 'Ebola', 'fatality', 'rate', '50', 'percent', '.'], ['But', 'rate', 'varied', '25', 'percent', '90', 'percent', 'recent', 'outbreak', '.'], ['There', 'yet', 'proven', 'cure', 'available', 'Ebola', ',', 'though', 'vaccine', 'tested', '.'], ['Some', 'people', 'recovered', 'Ebola', 'developed', 'long-term', 'complication', ',', 'joint', 'vision', 'problem', '.'], ['It', 'known', 'people', 'recover', 'Ebola', 'succumb', 'disease', '.'], ['Why', 'keep', 'coming', 'back', '?'], ['The', 'disease', 'infects', 'human', 'close', 'contact', 'infected', 'animal', ',', 'including', 'chimpanzee', ',', 'fruit', 'bat', 'forest', 'antelope', '.'], ['In', 'Africa', 'outbreak', 'happen', ',', 'particular', 'specie', 'fruit', 'bat', 'considered', 'natural', 'host', 'Ebola', 'virus', '.'], ['Infected', 'bat', 'believed', 'transmit', 'disease', 'human', ',', 'indirectly', 'animal', 'hunted', 'meat', '.'], ['The', 'family', 'first', 'victim', '2014', 'outbreak', ',', 'two-year-old', 'child', ',', 'hunted', 'bat', 'believed', 'bushmeat', 'origin', 'outbreak', '.'], ['An', 'estimated', 'five', 'million', 'tonne', 'bushmeat', 'consumed', 'continent', 'every', 'year', ',', 'according', 'Centre', 'International', 'Forestry', 'Research', '.'], ['The', 'virus', 'spread', 'human', 'direct', 'contact', 'infected', 'blood', ',', 'bodily', 'fluid', 'organ', ',', 'indirectly', 'contact', 'contaminated', 'environment', '.'], ['Even', 'funeral', 'Ebola', 'victim', 'risk', ',', 'mourner', 'direct', 'contact', 'body', 'deceased', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Stemming and Lemmatization\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "preprocessed_docs = []\n",
    "\n",
    "for doc in tokenized_docs_no_stopwords:\n",
    "    final_doc = []\n",
    "    for word in doc:\n",
    "        #final_doc.append(porter.stem(word))\n",
    "        final_doc.append(wordnet.lemmatize(word))\n",
    "    preprocessed_docs.append(final_doc)\n",
    "\n",
    "print(preprocessed_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: Prep Data (split into train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, test = train_test_split(reviews, train_size=0.7, random_state = 42 ) \n",
    "# len(training)\n",
    "# print(len(test)) # 70% of traning set\n",
    "\n",
    "developmentSet, testSet = train_test_split(test, train_size=0.5, random_state = 42 ) \n",
    "# print(len(testSet)) # 15% of test set\n",
    "# print(len(developmentSet)) # 15% of development set\n",
    "# print(developmentSet[0].sentence)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "developmentSet_container = ReviewContainer(developmentSet)\n",
    "testSet_container = ReviewContainer(testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: Seperate the attribute, originally our array has text and score. we want them to be a seperate array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Positive Propaganda:\n3780\n\nNegative Propaganda:\n3780\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_sentence = train_container.get_sentence()    # return just text\n",
    "train_propaganda = train_container.get_propaganda()   # return just sentiment\n",
    "\n",
    "development_sentence = developmentSet_container.get_sentence() \n",
    "development_propaganda = developmentSet_container.get_propaganda() \n",
    "\n",
    "testSet_container.evenly_distribute()\n",
    "test_sentence = testSet_container.get_sentence() \n",
    "test_propaganda = testSet_container.get_propaganda() \n",
    "\n",
    "print(\"Positive Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "print(\"\\nNegative Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "im already having this anxiety attack over security and im already just like on high alert and now paparazzis found us its like just the scrutiny that we get all the time we try to avoid that she said\n[[0 0 0 ... 0 0 0]]\n[[0 0 0 ... 0 0 0]]\n[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_sentence) # return a matrix of either 0 or 1 # train_x is our text\n",
    "test_x_vectors = vectorizer.transform(test_sentence)\n",
    "\n",
    "# Todo:\n",
    "# transform development set to vectors\n",
    "development_x_vectors = vectorizer.fit_transform(development_sentence)\n",
    "print(train_sentence[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "print(test_x_vectors[0].toarray())\n",
    "print(development_x_vectors[0].toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf',C=1)\n",
    "clf_svm.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "\n",
    "\n",
    "clf_svm.predict(test_x_vectors[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray() , train_propaganda)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_log.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Accuracy\n",
    "# For Support Vector Machine\n",
    "print(clf_svm.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Tree\n",
    "print(clf_dec.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Naive Bayes\n",
    "print(clf_gnb.score(test_x_vectors.toarray(),test_propaganda))\n",
    "# For Logistic Regression\n",
    "print(clf_log.score(test_x_vectors,test_propaganda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(test_propaganda, clf_svm.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels\n",
    "\n",
    "# For Support Decision Tree\n",
    "print(f1_score(test_propaganda,clf_dec.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Support Naive Bayes\n",
    "print(f1_score(test_propaganda,clf_gnb.predict(test_x_vectors.toarray()),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Logistic Regression\n",
    "print(f1_score(test_propaganda,clf_log.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# check number of positive and negative classes in training set\n",
    "print(\"Number of NEGATIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n",
    "print(\"Number of POSITIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "\n",
    "# check number of positive and negative classes in test set\n",
    "y = np.array(test_propaganda)\n",
    "number_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "number_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in test set:\")\n",
    "print(number_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in test set:\")\n",
    "print(number_of_POSITIVE)\n",
    "\n",
    "# check number of positive and negative classes in development set\n",
    "\n",
    "y = np.array(development_propaganda)\n",
    "Dnumber_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "Dnumber_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in development set:\")\n",
    "print(Dnumber_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in development set:\")\n",
    "print(Dnumber_of_POSITIVE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set =['this is advertisement','bad book do not buy','horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 7: Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuned = svm.SVC()\n",
    "parameters = {'kernel':('linear','rbf'),'C':(1,4,8,16,32,64)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameters,cv=10)\n",
    "clf.fit(train_x_vectors,train_propaganda)\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}