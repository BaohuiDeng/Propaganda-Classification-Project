{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Install spacy and it's predefined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy\n",
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('~/anaconda3/MasterProject/Dataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "sentenceArray = [ x.sentence for x  in reviews] \n",
    "print(sentenceArray)\n",
    "print(len(sentenceArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vector =[]\n",
    "for x in sentenceArray:\n",
    "    sentence_vector.append(get_vec(x))\n",
    "sentence_vector[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(x)\n",
    "def get_vec(x):\n",
    "      doc = nlp(x)\n",
    "      vec = doc.vector\n",
    "      return vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
=======
>>>>>>> d625e5b9801ef2e0dd51ef2231e30a8135489186
    "# step 1: Predefined CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Propaganda:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,sentence,SUBJprop):\n",
    "        self.sentence = sentence\n",
    "        self.SUBJprop = SUBJprop\n",
    "        self.propaganda = self.get_propaganda()        \n",
    "\n",
    "    def get_propaganda(self):\n",
    "        if int(self.SUBJprop) <=3 :\n",
    "            return Propaganda.NEGATIVE\n",
    "        else:\n",
    "            return Propaganda.POSITIVE\n",
    "\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_sentence(self):\n",
    "        return [x.sentence for x  in self.reviews]\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        return [x.propaganda for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, self.reviews))\n",
    "        negative_shrunk = negative[:len(positive)]\n",
    "        self.reviews = positive + negative_shrunk\n",
    "        random.shuffle(self.reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows:\n",
      "3302\n",
      "Total Positive:\n",
      "105\n",
      "Total Negative:\n",
      "3197\n",
      "miley and liam fighting false rumors swirl that theyre in a feud over a supposed prenup\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('~/anaconda3/MasterProject/Dataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "\n",
    "\n",
    "print(\"Total Rows:\")\n",
    "print(len(reviews))\n",
    "print(\"Total Positive:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))))\n",
    "print(\"Total Negative:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))))\n",
    "\n",
    "# print(reviews[0].getSUBJprop)\n",
    "# sentenceArray = [ x.sentence for x  in reviews] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Prep Data (split into train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "neg_prop = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))\n",
    "pos_prop = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))\n",
    "\n",
    "########################################################################################\n",
    "#split trainig and DevTest dataset\n",
    "neg_train, neg_devtest  = train_test_split(neg_prop , train_size=0.7, random_state = 42 )\n",
    "pos_train, pos_devtest = train_test_split(pos_prop , train_size=0.7, random_state = 42 )\n",
    "########################################################################################\n",
    "#prepare training dataset\n",
    "train = neg_train + pos_train\n",
    "random.shuffle(train)\n",
    "########################################################################################\n",
    "#prepare development and test dataset\n",
    "neg_dev, neg_test = train_test_split(neg_devtest , train_size=0.5, random_state = 42 )\n",
    "pos_dev, pos_test = train_test_split(pos_devtest , train_size=0.5, random_state = 42 )\n",
    "\n",
    "dev = neg_dev + pos_dev\n",
    "random.shuffle(dev)\n",
    "\n",
    "test = neg_test + pos_test\n",
    "random.shuffle(test)\n",
    "########################################################################################\n",
    "print(\"Total Train:\")\n",
    "print(len(train))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_train))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_train))\n",
    "\n",
    "print(\"\\nTotal Development:\")\n",
    "print(len(dev))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_dev))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_dev))\n",
    "\n",
    "print(\"\\nTotal Test:\")\n",
    "print(len(test))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_test))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: Seperate the attribute, originally our array has text and score. we want them to be a seperate array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_container = ReviewContainer(train)\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "train_sentence = train_container.get_sentence()   \n",
    "train_propaganda = train_container.get_propaganda() \n",
    "\n",
    "development_sentence = [x.sentence for x in dev]\n",
    "development_propaganda = [x.propaganda for x in dev]\n",
    "\n",
    "test_sentence = [x.sentence for x in test]\n",
    "test_propaganda = [x.propaganda for x in test]\n",
    "\n",
    "print(\"Toalt rows after balance training dataset:\")\n",
    "print(len(train_sentence))\n",
    "\n",
    "print(\"Positive Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "print(\"Negative Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))"
   ]
  },
  {
   "source": [
    "# Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold cross validation\n",
    "# Basic example (MORE INFO)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf=KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(train_sentence):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#StratifiedKFold is better when we have unbalanced data, it makes sure that in training there is sufficient for the smallest class\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# KFold cross validation - on our dataset\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=2)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_nb = []\n",
    "\n",
    "# passong training dataset to Cross Validation\n",
    "Sample_Array_sentence = train_sentence\n",
    "Sample_Array_propaganda = train_propaganda\n",
    "\n",
    "\n",
    "# Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "Sample_Array_sentence_vectors = vectorizer.fit_transform(Sample_Array_sentence)\n",
    "\n",
    "\n",
    "for train_index, test_index in folds.split(Sample_Array_sentence_vectors,Sample_Array_propaganda):\n",
    "    X_train, X_test, y_train, y_test = Sample_Array_sentence_vectors[train_index], Sample_Array_sentence_vectors[test_index], \\\n",
    "                                       Sample_Array_propaganda[train_index], Sample_Array_propaganda[test_index]\n",
    "\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X_train, X_test, y_train, y_test))  \n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))\n",
    "    scores_nb.append(get_score(GaussianNB(), X_train.toarray(), X_test.toarray(), y_train, y_test))\n",
    "\n",
    "\n",
    "print(\"Score of Logistic Regression\")\n",
    "print(scores_logistic)\n",
    "print(\"Score of SVM\")\n",
    "print(scores_svm)\n",
    "print(\"Score of RandomForest\")\n",
    "print(scores_rf)\n",
    "print(\"Score of Naive Bayes\")\n",
    "print(scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same what we have done before but with the Sklearn Package\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "# cross_val_score(SVC(gamma='auto'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "# cross_val_score(RandomForestClassifier(n_estimators=40),Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_sentence) # return a matrix of either 0 or 1 # train_x is our text\n",
    "test_x_vectors = vectorizer.transform(test_sentence)\n",
    "\n",
    "# Todo:\n",
    "# transform development set to vectors\n",
    "development_x_vectors = vectorizer.fit_transform(development_sentence)\n",
    "print(train_sentence[0])\n",
    "print(train_x_vectors[2517].toarray())\n",
    "print(len(train_x_vectors.toarray()))\n",
    "\n",
    "print(test_x_vectors[0].toarray())\n",
    "print(len(test_x_vectors.toarray()))\n",
    "\n",
    "print(development_x_vectors[0].toarray())\n",
    "print(len(development_x_vectors.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf',C=1, probability=True)\n",
    "clf_svm.fit(train_x_vectors, train_propaganda)\n",
    "clf_svm.predict(test_x_vectors[1])\n",
    "\n",
    "# SVMProbabilityPropaganda=[]\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# while i < len(development_x_vectors.toarray()):\n",
    "#   SVMProbabilityPropaganda.append(clf_svm.predict_proba(development_x_vectors[i]))\n",
    "#   i += 1\n",
    "# IndexError: row index (2517) out of range\n",
    "\n",
    "# SVMProbabilityPropaganda.append(clf_svm.predict_proba(test_x_vectors[0]))\n",
    "\n",
    "\n",
    "# print('the first item in array')\n",
    "# print(SVMProbabilityPropaganda[0])\n",
    "# print('the whole Array')\n",
    "# print(SVMProbabilityPropaganda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "vector = model.wv['wedding']\n",
    "sims = model.wv.most_similar('wedding', topn=10)\n",
    "print(sims)\n",
    "# drawbacks on traing on own dataset: model has been triain on these words only, do not know\n",
    "# other words, hard to get meaningful result from your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "## svm\n",
    "clf_svm = svm.SVC(kernel='rbf',C=1)\n",
    "clf_svm.fit(train_x_vectors, train_propaganda)\n",
    "#clf_svm.predict(test_x_vectors[11])\n",
    "\n",
    "## decision tree\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "#clf_dec.predict(test_x_vectors[1])\n",
    "\n"
=======
    "# print(SVMProbabilityPropaganda[0])\n",
    "# print(SVMProbabilityPropaganda[0][0])\n",
    "# print(SVMProbabilityPropaganda[0][0][0])"
>>>>>>> d625e5b9801ef2e0dd51ef2231e30a8135489186
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray() , train_propaganda)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_log.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=1900.072243346008, pvalue=1.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "chi = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = int(row['SUBJprop'])\n",
    "    chi.append(prop)\n",
    "\n",
    "print(chisquare(chi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Accuracy\n",
    "# For Support Vector Machine\n",
    "print(clf_svm.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Tree\n",
    "print(clf_dec.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Naive Bayes\n",
    "print(clf_gnb.score(test_x_vectors.toarray(),test_propaganda))\n",
    "# For Logistic Regression\n",
    "print(clf_log.score(test_x_vectors,test_propaganda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(test_propaganda, clf_svm.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels\n",
    "\n",
    "# For Support Decision Tree\n",
    "print(f1_score(test_propaganda,clf_dec.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Support Naive Bayes\n",
    "print(f1_score(test_propaganda,clf_gnb.predict(test_x_vectors.toarray()),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Logistic Regression\n",
    "print(f1_score(test_propaganda,clf_log.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# check number of positive and negative classes in training set\n",
    "print(\"Number of NEGATIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n",
    "print(\"Number of POSITIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "\n",
    "# check number of positive and negative classes in test set\n",
    "y = np.array(test_propaganda)\n",
    "number_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "number_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in test set:\")\n",
    "print(number_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in test set:\")\n",
    "print(number_of_POSITIVE)\n",
    "\n",
    "# check number of positive and negative classes in development set\n",
    "\n",
    "y = np.array(development_propaganda)\n",
    "Dnumber_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "Dnumber_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in development set:\")\n",
    "print(Dnumber_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in development set:\")\n",
    "print(Dnumber_of_POSITIVE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 7: Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuned = svm.SVC()\n",
    "parameters = {'kernel':('linear','rbf'),'C':(1,4,8,16,32,64)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameters,cv=10)\n",
    "clf.fit(train_x_vectors,train_propaganda)\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "name": "python385jvsc74a57bd0cafe0eb33a5b748aef708b3398fce0f2e899e1701441dfed3bd3048456ea6d64",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
>>>>>>> d625e5b9801ef2e0dd51ef2231e30a8135489186
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
<<<<<<< HEAD
=======
  },
  "orig_nbformat": 3,
  "metadata": {
   "interpreter": {
    "hash": "030fe2e537001a0f06a091970833f1c1ec5f59e52d4488afbdc2cc8dde6768f5"
   }
>>>>>>> d625e5b9801ef2e0dd51ef2231e30a8135489186
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
