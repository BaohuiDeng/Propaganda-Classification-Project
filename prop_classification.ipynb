{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install spacy and it's predefined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy\n",
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('~/anaconda3/MasterProject/Dataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "sentenceArray = [ x.sentence for x  in reviews] \n",
    "print(sentenceArray)\n",
    "print(len(sentenceArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vector =[]\n",
    "for x in sentenceArray:\n",
    "    sentence_vector.append(get_vec(x))\n",
    "sentence_vector[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(x)\n",
    "def get_vec(x):\n",
    "      doc = nlp(x)\n",
    "      vec = doc.vector\n",
    "      return vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: Predefined CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Propaganda:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,sentence,SUBJprop):\n",
    "        self.sentence = sentence\n",
    "        self.SUBJprop = SUBJprop\n",
    "        self.propaganda = self.get_propaganda()        \n",
    "\n",
    "    def get_propaganda(self):\n",
    "        if int(self.SUBJprop) <=3 :\n",
    "            return Propaganda.NEGATIVE\n",
    "        else:\n",
    "            return Propaganda.POSITIVE\n",
    "\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_sentence(self):\n",
    "        return [x.sentence for x  in self.reviews]\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        return [x.propaganda for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, self.reviews))\n",
    "        negative_shrunk = negative[:len(positive)]\n",
    "        self.reviews = positive + negative_shrunk\n",
    "        random.shuffle(self.reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows:\n",
      "3302\n",
      "Total Positive:\n",
      "105\n",
      "Total Negative:\n",
      "3197\n",
      "miley and liam fighting false rumors swirl that theyre in a feud over a supposed prenup\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('~/anaconda3/MasterProject/Dataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "\n",
    "\n",
    "print(\"Total Rows:\")\n",
    "print(len(reviews))\n",
    "print(\"Total Positive:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))))\n",
    "print(\"Total Negative:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))))\n",
    "\n",
    "print(reviews[0].sentence)\n",
    "# sentenceArray = [ x.sentence for x  in reviews] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: Prep Data (split into train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train:\n",
      "11741\n",
      "Positive:\n",
      "2646\n",
      "Negative:\n",
      "9095\n",
      "\n",
      "Total Development:\n",
      "2516\n",
      "Positive:\n",
      "567\n",
      "Negative:\n",
      "1949\n",
      "\n",
      "Total Test:\n",
      "2517\n",
      "Positive:\n",
      "567\n",
      "Negative:\n",
      "1950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "neg_prop = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))\n",
    "pos_prop = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))\n",
    "\n",
    "########################################################################################\n",
    "#split trainig and DevTest dataset\n",
    "neg_train, neg_devtest  = train_test_split(neg_prop , train_size=0.7, random_state = 42 )\n",
    "pos_train, pos_devtest = train_test_split(pos_prop , train_size=0.7, random_state = 42 )\n",
    "########################################################################################\n",
    "#prepare training dataset\n",
    "train = neg_train + pos_train\n",
    "random.shuffle(train)\n",
    "########################################################################################\n",
    "#prepare development and test dataset\n",
    "neg_dev, neg_test = train_test_split(neg_devtest , train_size=0.5, random_state = 42 )\n",
    "pos_dev, pos_test = train_test_split(pos_devtest , train_size=0.5, random_state = 42 )\n",
    "\n",
    "dev = neg_dev + pos_dev\n",
    "random.shuffle(dev)\n",
    "\n",
    "test = neg_test + pos_test\n",
    "random.shuffle(test)\n",
    "########################################################################################\n",
    "print(\"Total Train:\")\n",
    "print(len(train))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_train))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_train))\n",
    "\n",
    "print(\"\\nTotal Development:\")\n",
    "print(len(dev))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_dev))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_dev))\n",
    "\n",
    "print(\"\\nTotal Test:\")\n",
    "print(len(test))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_test))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: Seperate the attribute, originally our array has text and score. we want them to be a seperate array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after balance training dataset:\n",
      "5292\n",
      "Positive Propaganda:\n",
      "2646\n",
      "Negative Propaganda:\n",
      "2646\n"
     ]
    }
   ],
   "source": [
    "train_container = ReviewContainer(train)\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "train_sentence = train_container.get_sentence()   \n",
    "train_propaganda = train_container.get_propaganda() \n",
    "\n",
    "development_sentence = [x.sentence for x in dev]\n",
    "development_propaganda = [x.propaganda for x in dev]\n",
    "\n",
    "test_sentence = [x.sentence for x in test]\n",
    "test_propaganda = [x.propaganda for x in test]\n",
    "\n",
    "print(\"Total rows after balance training dataset:\")\n",
    "print(len(train_sentence))\n",
    "\n",
    "print(\"Positive Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "print(\"Negative Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold cross validation\n",
    "# Basic example (MORE INFO)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf=KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(train_sentence):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Score of Logistic Regression\n",
      "[0.5783811475409836, 0.5655737704918032]\n",
      "Score of SVM\n",
      "[0.5883709016393442, 0.5886270491803278]\n",
      "Score of RandomForest\n",
      "[0.5868340163934426, 0.5750512295081968]\n",
      "Score of Naive Bayes\n",
      "[0.5258709016393442, 0.5317622950819673]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#StratifiedKFold is better when we have unbalanced data, it makes sure that in training there is sufficient for the smallest class\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# import spacy\n",
    "# import en_core_web_sm\n",
    "# nlp = en_core_web_sm.load()\n",
    "# def get_vec(x):\n",
    "#       doc = nlp(x)\n",
    "#       vec = doc.vector\n",
    "#       return vec\n",
    "\n",
    "# KFold cross validation - on our dataset\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=2)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_nb = []\n",
    "Sample_Array_sentence_vectors=[]\n",
    "Sample_Array_sentence = np.concatenate((train_sentence, development_sentence))\n",
    "Sample_Array_propaganda = np.concatenate((train_propaganda, development_propaganda))\n",
    "Sample_Array_sentence_Array =Sample_Array_sentence.tolist()\n",
    "print(type(Sample_Array_sentence_Array))\n",
    "\n",
    "#Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "Sample_Array_sentence_vectors = vectorizer.fit_transform(Sample_Array_sentence)\n",
    "\n",
    "\n",
    "# # Word2Vec\n",
    "# for x in Sample_Array_sentence_Array:\n",
    "#     Sample_Array_sentence_vectors.append(get_vec(x))\n",
    "\n",
    "\n",
    "for train_index, test_index in folds.split(Sample_Array_sentence_vectors,Sample_Array_propaganda):\n",
    "    X_train, X_test, y_train, y_test = Sample_Array_sentence_vectors[train_index], Sample_Array_sentence_vectors[test_index], \\\n",
    "                                       Sample_Array_propaganda[train_index], Sample_Array_propaganda[test_index]\n",
    "\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X_train, X_test, y_train, y_test))  \n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))\n",
    "    scores_nb.append(get_score(GaussianNB(), X_train.toarray(), X_test.toarray(), y_train, y_test))\n",
    "\n",
    "\n",
    "print(\"Score of Logistic Regression\")\n",
    "print(scores_logistic)\n",
    "print(\"Score of SVM\")\n",
    "print(scores_svm)\n",
    "print(\"Score of RandomForest\")\n",
    "print(scores_rf)\n",
    "print(\"Score of Naive Bayes\")\n",
    "print(scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same what we have done before but with the Sklearn Package\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "cross_val_score(SVC(gamma='auto'), Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)\n",
    "cross_val_score(RandomForestClassifier(n_estimators=40),Sample_Array_sentence_vectors, Sample_Array_propaganda,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2/5 NLTK with independent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# word tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_docs = [word_tokenize(doc) for doc in sentenceArray_final]\n",
    "\n",
    "print(tokenized_docs[1])\n",
    "print(\"#######################################################################################\")\n",
    "\n",
    "#Sentence tokenization\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_token = [sent_tokenize(doc) for doc in sentenceArray_final]\n",
    "print(sent_token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Cleaning text of stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenized_docs_no_stopwords = []\n",
    "\n",
    "for doc in tokenized_docs:\n",
    "    new_term_vector = []\n",
    "    for word in doc:\n",
    "        if not word in stopwords.words('english'):\n",
    "            new_term_vector.append(word)\n",
    "    tokenized_docs_no_stopwords.append(new_term_vector)\n",
    "\n",
    "print(tokenized_docs_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Stemming and Lemmatization\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "preprocessed_docs = []\n",
    "\n",
    "for doc in tokenized_docs_no_stopwords:\n",
    "    final_doc = []\n",
    "    for word in doc:\n",
    "        #final_doc.append(porter.stem(word))\n",
    "        final_doc.append(wordnet.lemmatize(word))\n",
    "    preprocessed_docs.append(final_doc)\n",
    "\n",
    "print(preprocessed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# train_x_vectors = vectorizer.fit_transform(train_sentence) # return a matrix of either 0 or 1 # train_x is our text\n",
    "# test_x_vectors = vectorizer.transform(test_sentence)\n",
    "\n",
    "# # Todo:\n",
    "# # transform development set to vectors\n",
    "# development_x_vectors = vectorizer.fit_transform(development_sentence)\n",
    "# print(train_sentence[0])\n",
    "# print(train_x_vectors[0].toarray())\n",
    "# print(test_x_vectors[0].toarray())\n",
    "# print(development_x_vectors[0].toarray())\n",
    "## spacy word2vec\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "def get_vec(x):\n",
    "      doc = nlp(x)\n",
    "      vec = doc.vector\n",
    "      return vec\n",
    "# Word2Vec\n",
    "train_x_vectors = []\n",
    "for x in train_sentence:\n",
    "     train_x_vectors.append(get_vec(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Word2Vec Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,keyedvectors\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "clean_sentence = []\n",
    "for sentence in sentenceArray:\n",
    "    clean_sentence.append(gensim.utils.simple_preprocess(sentence))\n",
    "print(clean_sentence[3])\n",
    "\n",
    "# min_count: consider a word as input if it occurs minimun 5 times\n",
    "# vector_size: means number of features a word capture like cat [] has feature animal 0.9 and furniture 0.01\n",
    "\n",
    "model = Word2Vec(clean_sentence,vector_size=150,window=10,min_count=5,workers=10)\n",
    "model.train(clean_sentence,total_examples=len(clean_sentence),epochs=10)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.wv['wedding']\n",
    "sims = model.wv.most_similar('wedding', topn=10)\n",
    "print(sims)\n",
    "# drawbacks on traing on own dataset: model has been triain on these words only, do not know\n",
    "# other words, hard to get meaningful result from your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "## svm\n",
    "clf_svm = svm.SVC(kernel='rbf',C=1)\n",
    "clf_svm.fit(train_x_vectors, train_propaganda)\n",
    "#clf_svm.predict(test_x_vectors[11])\n",
    "\n",
    "## decision tree\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "#clf_dec.predict(test_x_vectors[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# clf_dec = DecisionTreeClassifier()\n",
    "# clf_dec.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "# clf_dec.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray() , train_propaganda)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_propaganda)\n",
    "\n",
    "clf_log.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: Chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=1900.072243346008, pvalue=1.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "chi = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = int(row['SUBJprop'])\n",
    "    chi.append(prop)\n",
    "\n",
    "print(chisquare(chi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-93252825e12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mean Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# # For Support Vector Machine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x_vectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_propaganda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# For Decision Tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x_vectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_propaganda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_x_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "# # For Support Vector Machine\n",
    "print(clf_svm.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Tree\n",
    "print(clf_dec.score(test_x_vectors,test_propaganda))\n",
    "# For Decision Naive Bayes\n",
    "# print(clf_gnb.score(test_x_vectors.toarray(),test_propaganda))\n",
    "# # For Logistic Regression\n",
    "# print(clf_log.score(test_x_vectors,test_propaganda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Support Vector Machine\n",
    "print(f1_score(test_propaganda, clf_svm.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "# trash for negative and neutral labels\n",
    "\n",
    "# For Support Decision Tree\n",
    "print(f1_score(test_propaganda,clf_dec.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Support Naive Bayes\n",
    "print(f1_score(test_propaganda,clf_gnb.predict(test_x_vectors.toarray()),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n",
    "\n",
    "# For Logistic Regression\n",
    "print(f1_score(test_propaganda,clf_log.predict(test_x_vectors),average = None, \n",
    "labels=[Propaganda.POSITIVE,Propaganda.NEGATIVE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# check number of positive and negative classes in training set\n",
    "print(\"Number of NEGATIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n",
    "print(\"Number of POSITIVE in training set:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "\n",
    "# check number of positive and negative classes in test set\n",
    "y = np.array(test_propaganda)\n",
    "number_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "number_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in test set:\")\n",
    "print(number_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in test set:\")\n",
    "print(number_of_POSITIVE)\n",
    "\n",
    "# check number of positive and negative classes in development set\n",
    "\n",
    "y = np.array(development_propaganda)\n",
    "Dnumber_of_NEGATIVE = (y == \"NEGATIVE\").sum()\n",
    "Dnumber_of_POSITIVE = (y == \"POSITIVE\").sum()\n",
    "print(\"\\nNumber of NEGATIVE in development set:\")\n",
    "print(Dnumber_of_NEGATIVE)\n",
    "print(\"Number of POSITIVE in development set:\")\n",
    "print(Dnumber_of_POSITIVE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set =['this is advertisement','bad book do not buy','horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 7: Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuned = svm.SVC()\n",
    "parameters = {'kernel':('linear','rbf'),'C':(1,4,8,16,32,64)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameters,cv=10)\n",
    "clf.fit(train_x_vectors,train_propaganda)\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
